<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Document</title>
  <link rel="stylesheet" href="css/main.css">
</head>

<body>
  <h2><strong>Для студентов с программой Data Science онлайн или в записи</strong></h2>
  <h2><strong>Python</strong></h2>

  <!-- 1 -->
  <details class="details">
    <summary class="details__title">Встроенные типы данных Python. Функция type(). Приведение типов.</summary>
    <div class="details__content">
      <p>Python имеет несколько встроенных типов данных, которые можно разделить на категории:</p>
      <ol>
        <li>
          <p><b>Числовые типы:</b><br><u>int:</u> Целые числа (например, 1, -5, 42)<br><u>float:</u> Числа с плавающей
            запятой (например, 3.14, -0.001, 2.0)<br><u>complex:</u> Комплексные числа (например, 1+2j, 3-4j)</p>
        </li>
        <li>
          <p>
            <b>Логический тип:</b><br><u>bool:</u> Логические значения (True, False)
          </p>
        </li>
        <li>
          <p>
            <b>Последовательности:</b><br><u>str:</u> Строки (например, "hello", "Python")<br><u>list:</u> Списки
            (например, [1, 2, 3], ["a", "b", "c"])<br><u>tuple:</u> Кортежи (например, (1, 2, 3), ("a", "b",
            "c"))<br><u>range:</u> Диапазоны (например, range(10), range(1, 5, 2))
          </p>
        </li>
        <li>
          <b>Коллекции:</b><br><u>set:</u> Множества (например, {1, 2, 3}, {"a", "b", "c"})<br><u>frozenset:</u>
          Неизменяемые множества (например, frozenset([1, 2, 3]))<br><u>dict:</u> Словари (например, {"key": "value",
          "name": "John"})
        </li>
        <li>
          <p>
            <b>Специальные типы:</b><br><u>NoneType:</u> Специальный тип, представляющий отсутствие значения или null
            (например, None)
          </p>
        </li>
      </ol>
      </p>

      <p><br><b>Функция type()</b> используется для определения типа объекта. Также type() может быть использована для создания новых типов (классов) динамически. Пример:</p>
      <code>
        &nbsp;&nbsp;&nbsp;&nbsp;MyClass = type('MyClass', (object,), {'attr': 42})<br>
        &nbsp;&nbsp;&nbsp;&nbsp;obj = MyClass()<br>
        &nbsp;&nbsp;&nbsp;&nbsp;print(obj.attr)  # 42<br>
      </code>

      <p><br><b>Приведение типов (или преобразование типов)</b> — это процесс преобразования значения из одного типа данных в другой. Python предоставляет несколько встроенных функций для приведения типов
      <br>list(), tuple(), set(), dict(), str(), int(), float(), bool()</p>
    </div>
  </details>

  <!-- 2 -->
  <details class="details">
    <summary class="details__title">Условный оператор.</summary>
    <div class="details__content">
      <p>Условный оператор используется для выполнения блока кода в зависимости от выполнения условия. В Python основным условным оператором является if, который можно комбинировать с elif (сокращение от "else if") и else для создания сложных условных конструкций.</p>
      <p><b>Тернарный оператор</b> - Python также поддерживает условные выражения, которые позволяют записывать условные операторы в одну строку.</p>
    </div>
  </details>

  <!-- 3 -->
  <details class="details">
    <summary class="details__title">Арифметические и логические операции.</summary>
    <div class="details__content">
      <p><b>Арифметические операции</b> используются для выполнения математических вычислений. Python поддерживает следующие арифметические операции:</p>
      <ol>
        <li>Сложение (+)</li>
        <li>Вычитание (-)</li>
        <li>Умножение (*)</li>
        <li>Деление (/)</li>
        <li>Целочисленное деление (//)</li>
        <li>Остаток от деления (%)</li>
        <li>Возведение в степень (**)</li>
      </ol>
      <p><b>Логические операции</b> используются для выполнения логических вычислений. В Python есть следующие логические операторы:</p>
      <ol>
        <li>Логическое "и" (and) - Возвращает True, если оба выражения истинн</li>
        <li>Логическое "или" (or) - Возвращает True, если хотя бы одно из выражений истинно.</li>
        <li>Логическое "не" (not) - Возвращает True, если выражение ложно, и False, если выражение истинно.</li>
      </ol>
      <p><b>Сравнительные операторы</b> используются для сравнения значений. Они часто используются в логических выражениях и условных операторах.</p>
      <ol>
        <li>Равно (==)</li>
        <li>Не равно (!=)</li>
        <li>Меньше (<)</li>
        <li>Больше (>)</li>
        <li>Меньше или равно (<=)</li>
        <li>Больше или равно (>=)</li>
      </ol>
    </div>
  </details>

  <!-- 4 -->
  <details class="details">
    <summary class="details__title">Коллекции данных: типы tuple, list, dict,set.</summary>
    <div class="details__content">
      <p>Python предоставляет несколько встроенных типов коллекций, которые позволяют хранить и управлять группами данных. <br>К основным коллекциям данных относятся:<br></p>
      <ol>
        <li>
          <p><b>Кортежи (tuple)</b> - Кортежи представляют собой <b>неизменяемые</b> последовательности. Это означает, что после создания кортежа его элементы нельзя изменять, добавлять или удалять.</p>
          <ul><b>Основные операции</b>
            <li>Конкатенация: <code>new_tuple = my_tuple + another_tuple</code></li>
            <li>Повторение: <code>repeated_tuple = my_tuple * 3</code></li>
            <li>Проверка на наличие элемента: <code>is_in = 2 in my_tuple</code></li>
          </ul>
        </li>
        <li>
          <p><b>Списки (list)</b> - Списки представляют собой <b>изменяемые</b> последовательности. Это означает, что после создания списка его элементы можно изменять, добавлять или удалять.</p>
          <ul><b>Основные операции</b>
            <li>Добавление элемента: <code>my_list.append(4)</code></li>
            <li>Вставка элемента: <code>my_list.insert(1, 10)</code></li>
            <li>Удаление элемента по значению: <code>my_list.remove(2)</code></li>
            <li>Удаление элемента по индексу: <code>del my_list[0]</code> или <code>my_list.pop(0)</code></li>
            <li>Конкатенация: <code>new_list = my_list + another_list</code></li>
            <li>Повторение: repeated_list = <code>my_list * 3</code></li>
            <li>Проверка на наличие элемента: <code>is_in = 2 in my_list</code></li>
          </ul>
        </li>
        <li>
          <p><b>Словари (dict)</b> - Словари представляют собой коллекции пар ключ-значение. Ключи в словаре должны быть уникальными и неизменяемыми (например, строки, числа), а значения могут быть любыми.</p>
          <ul><b>Основные операции</b>
            <li>Добавление пары ключ-значение: <code>my_dict["gender"] = "male"</code></li>
            <li>Удаление пары ключ-значение: <code>del my_dict["age"]</code></li>
            <li>Проверка на наличие ключа: <code>is_in = "name" in my_dict</code></li>
            <li>Получение значения по ключу с значением по умолчанию: <code>value = my_dict.get("address", "unknown")</code></li>
          </ul>
        </li>
        <li>
          <p><b>Множества (set)</b> - Множества представляют собой неупорядоченные коллекции уникальных элементов. Они используются для выполнения математических операций над множествами, таких как объединение, пересечение и разность.</p>
          <ul><b>Основные операции</b>
            <li>Добавление элемента: <code>my_set.add(4)</code></li>
            <li>Удаление элемента: <code>my_set.remove(3)</code></li>
            <li>Объединение множеств: <code>union_set = my_set | another_set</code></li>
            <li>Пересечение множеств: <code>intersection_set = my_set & another_set</code></li>
            <li>Разность множеств: <code>difference_set = my_set - another_set</code></li>
            <li>Проверка на наличие элемента: <code>is_in = 2 in my_set</code></li>
          </ul>
        </li>
      </ol>
    </div>
  </details>

  <!-- 5 -->
  <details class="details">
    <summary class="details__title">Переменные Python. Правила именования переменных.</summary>
    <div class="details__content">
      <p>Переменные в Python используются для хранения данных, которые могут изменяться в течение выполнения программы.<br>
        <b>Переменная</b> — это именованная область памяти, которая содержит значение.<br>
        Для присваивания значения переменной используется оператор <b>`=`</b></p>
        <br>
        <ol><b>Правила именования переменных</b>
          <li>Имя переменной должно начинаться с буквы (a-z, A-Z) или символа подчеркивания (_)</li>
          <li>Остальные символы имени переменной могут быть буквами, цифрами или подчеркиваниями</li>
          <li>Имена переменных чувствительны к регистру. Это значит, что myVariable и myvariable будут разными переменными</li>
          <li>Нельзя использовать зарезервированные слова (ключевые слова) Python в качестве имен переменных. <br><b>Например</b>, такие слова как <u>False, True, None, and, or, if, else, for, while и другие нельзя использовать в качестве имен переменных</u></li>
        </ol>
        <br>
        <ol><b>Соглашения по стилю именования переменных</b>
          <li>Используйте <b>snake_case</b> для имен переменных:
            <ul>
              <li>Слова разделяются подчеркиваниями, все буквы в нижнем регистре.</li>
              <li>Пример: <b>user_age, total_sum, max_value.</b></li>
            </ul>
          </li>
          <li>Используйте <b>UPPER_CASE</b> для имен констант:
            <ul>
              <li>Пример: <b>PI, MAX_SIZE, MIN_VALUE.</b></li>
            </ul>
          </li>
          <li>Используйте <b>описательные имена</b> переменных:
            <ul>
              <li>Имена переменных должны отражать их смысл и предназначение.</li>
              <li>Пример: <b>user_age вместо ua, total_price вместо tp.</b></li>
            </ul>
          </li>
        </ol>
    </div>
  </details>

  <!-- 6 -->
  <details class="details">
    <summary class="details__title">Циклы for и while.</summary>
    <div class="details__content">
      <p>Циклы позволяют повторять блок кода несколько раз, что полезно для обработки коллекций данных, выполнения итераций и автоматизации задач.</p>
      <ol>
        <li>
          <b>Цикл for</b> - используется для итерации по элементам последовательности (например, списка, кортежа, строки, множества или словаря).<br>
          Основной синтаксис:<br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;<b>for</b> элемент <b>in</b> последовательность:<br>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;блок_кода
          </code>
        </li>
        <li>
          <b>Цикл while</b> - Цикл while выполняет блок кода до тех пор, пока условие истинно.<br>
          Основной синтаксис:<br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;<b>while</b> условие:<br>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;блок_кода
          </code>
        </li>
        <li><b>Операторы итераций циклов</b><br>
          <b>break</b> - Ключевое слово, которое прерывает выполнение текущего цикла. После использования break, остальные блоки кода текущего цикла не будут выполнены.<br>
          <b>continue</b> - Ключевое слово, которое прерывает текущую итерацию цикла
      </ol>
    </div>
  </details>

  <!-- 7 -->
  <details class="details">
    <summary class="details__title">Функции ввода/вывода данных Python (print(), input()).</summary>
    <div class="details__content">
      <p>
        <b>print(*args, sep=' ', end='\n', file=None, flush=False)</b> - Выводит значения в поток, или по умолчанию в sys.stdout.<br><br>
        <b>sep</b> - строка, вставляемая между значениями, по умолчанию пробел.<br>
        <b>end</b> - строка, добавляемая после последнего значения, по умолчанию - новая строка.<br>
        <b>file</b> - файлоподобный объект (поток); по умолчанию - текущий sys.stdout.<br>
        <b>flush</b> -очистка буфера
        </p>
        <br>
        <p>
          <b>input(prompt='')</b> - Чтение строки из стандартного ввода.  Заглавная новая строка удаляется. Строка запроса, если она задана, выводится на стандартный вывод без завершающей новой строки перед чтением ввода.
        </p>
    </div>
  </details>

  <!-- 8 -->
  <details class="details">
    <summary class="details__title">Пользовательские функции. Параметры функций.</summary>
    <div class="details__content">
      <p>Функции в Python позволяют структурировать код, улучшая его читаемость и повторное использование. Функции могут принимать параметры и возвращать значения.</p>
      <ol><b>Виды параметров</b>
        <li><b>Обязательные параметры:</b> Параметры, которые должны быть переданы функции.</li>
        <li><b>Необязательные параметры (с параметрами по умолчанию):</b> Параметры, которые могут быть пропущены. Если они пропущены, используется значение по умолчанию.</li>
        <li><b>Произвольное количество параметров:</b> Параметры, позволяющие передавать неопределенное количество аргументов.</li>
      </ol>
      <p><br><b>Область видимости переменных</b><br>Переменные, объявленные внутри функции, имеют локальную область видимости и недоступны за пределами функции. Переменные, объявленные вне функции, имеют глобальную область видимости.</b>
      <p><br><b>Вложенные функции</b> - Функции могут быть определены внутри других функций. Вложенные функции могут захватывать переменные из объемлющей области видимости.</p>
      <p><br><b>Анонимные функции (lambda)</b> - Python поддерживает создание анонимных функций с использованием ключевого слова lambda. Lambda-функции ограничены одним выражением и часто используются для создания небольших, одноразовых функций.</p>
      <p><br><b>Документация функций</b> - Для документирования функций в Python используется строка документации (docstring), которая помещается сразу после определения функции.</p>
    </div>
  </details>

  <!-- 9 -->
  <details class="details">
    <summary class="details__title">Библиотека Numpy. Индексация. Срезы.</summary>
    <div class="details__content">
      <p><b>NumPy (Numerical Python)</b> — это фундаментальная библиотека для научных вычислений в Python, которая предоставляет поддержку для массивов и матриц, а также высокоуровневые математические функции для работы с ними. <b>Все элементы в массиве NumPy должны быть однородными.</b></p>
      <p><b>Массив</b> — это центральная структура данных библиотеки NumPy. Массив представляет собой сетку значений и содержит информацию о необработанных данных, о том, как найти элемент и как его интерпретировать. Он имеет сетку элементов, которые можно индексировать различными способами . Все элементы одного типа, называемые массивом "dtype".</p>
      <br>
      <ol><b>Основные особенности NumPy</b>
        <li><b>Массивы (ndarray):</b> Основная структура данных в NumPy, которая позволяет работать с многомерными массивами.</li>
        <li><b>Высокопроизводительные операции:</b> NumPy оптимизирован для выполнения математических операций.</li>
        <li><b>Интеграция:</b> NumPy хорошо интегрируется с другими библиотеками, такими как SciPy, Matplotlib и pandas.</li>
      </ol>
      <br>
      <p>
        arr = np.array([1, 2, 3, 4, 5]) <span style="color: rgb(4, 93, 14); font-weight: bold;"># Создание массива из списка</span><br>
        zeros = np.zeros((2, 3))  <span style="color: rgb(4, 93, 14); font-weight: bold;"># 2x3 массив нулей</span><br>
        ones = np.ones((2, 3))  <span style="color: rgb(4, 93, 14); font-weight: bold;"># 2x3 массив единиц</span><br>
        eye = np.eye(3)  <span style="color: rgb(4, 93, 14); font-weight: bold;"># 3x3 единичная матрица</span><br>
        linspace = np.linspace(0, 1, 5)  <span style="color: rgb(4, 93, 14); font-weight: bold;"># 5 значений от 0 до 1 включительно</span><br>
        random_array = np.random.rand(2, 3)  <span style="color: rgb(4, 93, 14); font-weight: bold;"># 2x3 массив случайных значений</span><br>
      </p>
      <br>
      <p><b>Проверка типа данных: </b><span style="color: rgb(4, 93, 14); font-weight: bold;">print(arr.dtype)  # float32</span></p>
      <br>
      <table><tbody><tr><th data-colwidth="117" width="117"><p><strong>Тип данных</strong></p></th><th><p><strong>Описание</strong></p></th></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>bool</code></p></td><td><p align="left">Булевы значения (<code>True</code>&nbsp;или&nbsp;<code>False</code>) хранятся в виде байтов</p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>int</code></p></td><td><p align="left">Тип по умолчанию — целое число (то же, что&nbsp;<code>long</code>&nbsp;в C; обычно&nbsp;<code>int64</code>&nbsp;или&nbsp;<code>int32</code>)</p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>intc</code></p></td><td><p align="left">Идентичный&nbsp;<code>int</code>&nbsp;в C (обычно&nbsp;<code>int32</code>&nbsp;или&nbsp;<code>int64</code>)</p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>intp</code></p></td><td><p align="left">Целое число для использования в качестве индексов (то же, что и&nbsp;<code>size_t</code>&nbsp;в C, обычно&nbsp;<code>int32</code>&nbsp;или&nbsp;<code>int64</code>)</p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>int8</code></p></td><td><p align="left">Байт (от — 128 до 127)</p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>int16</code></p></td><td><p align="left">Целое число (от -32768 до 32767)</p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>int32</code></p></td><td><p align="left">Целое число (от -2147483648 до 2147483647)</p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>int64</code></p></td><td><p align="left">Целое число (от -9223372036854775808 до 9223372036854775807)</p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>uint8</code></p></td><td><p align="left">Целое число без знака (от 0 до 255)</p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>uint16</code></p></td><td><p align="left">Целое число без знака (от 0 до 65535)</p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>uint32</code></p></td><td><p align="left">Целое число без знака (от 0 до 4294967295)</p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>uint64</code></p></td><td><p align="left">Целое число без знака (от 0 до 18446744073709551615)</p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>float</code></p></td><td><p align="left">Обозначение&nbsp;<code>float64</code></p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>float16</code></p></td><td><p align="left">Число с плавающей точкой половинной точности; бит на знак, 5-битная экспонента, 10-битная мантисса</p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>float32</code></p></td><td><p align="left">Число с плавающей точкой единичной точности; бит на знак, 8-битная экспонента, 23-битная мантисса</p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>float64</code></p></td><td><p align="left">Число с плавающей точкой двойной точности; бит на знак, 11-битная экспонента, 52-битная мантисса</p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>complex</code></p></td><td><p align="left">Обозначение complex128</p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>complex64</code></p></td><td><p align="left">Комплексное число, представленное двумя 32-битными&nbsp;<code>float</code>&nbsp;(с действительной и мнимой частями)</p></td></tr><tr><td data-colwidth="117" width="117"><p align="left"><code>complex128</code></p></td><td><p align="left">Комплексное число, представленное двумя 64-битными&nbsp;<code>float</code>&nbsp;(с действительной и мнимой частями)</p></td></tr></tbody></table>      
      <br>
      <p>
        <b>Размерности массивов - </b>Массивы в NumPy могут иметь произвольное количество измерений. Размерности массива можно проверить с помощью атрибутов .ndim, .shape и .size.<br>
        &nbsp;&nbsp;&nbsp;&nbsp;arr = np.array([[1, 2, 3], [4, 5, 6]])<br>
        <br>
        &nbsp;&nbsp;&nbsp;&nbsp;print(arr.ndim)  <span style="color: rgb(4, 93, 14); font-weight: bold;"># 2 (двумерный массив)</span><br>
        &nbsp;&nbsp;&nbsp;&nbsp;print(arr.shape)  <span style="color: rgb(4, 93, 14); font-weight: bold;"># (2, 3) (2 строки, 3 столбца)</span><br>
        &nbsp;&nbsp;&nbsp;&nbsp;print(arr.size)  <span style="color: rgb(4, 93, 14); font-weight: bold;"># 6 (всего элементов)</span><br>
      </p>
      <br>
      <p>
        <b>Основные методы и операции</b><br>
        Арифметические операции - NumPy поддерживает векторизованные операции, которые выполняются над массивами элемент-wise <br>
        Универсальные функции (ufunc) - NumPy предоставляет множество универсальных функций, таких как np.sqrt, np.exp, np.sin и другие <br>
        <br><b>Методы для изменения формы массива</b> <br>
        &nbsp;&nbsp;&nbsp;&nbsp;arr = np.array([[1, 2, 3], [4, 5, 6]])<br>

        &nbsp;&nbsp;&nbsp;&nbsp;<span style="color: rgb(4, 93, 14); font-weight: bold;"># Транспонирование</span><br>
        &nbsp;&nbsp;&nbsp;&nbsp;print(arr.T)  # [[1 4]<br>
                      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#  [2 5]<br>
                      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#  [3 6]]<br>

        &nbsp;&nbsp;&nbsp;&nbsp;<span style="color: rgb(4, 93, 14); font-weight: bold;"># Изменение формы массива</span><br>
        &nbsp;&nbsp;&nbsp;&nbsp;reshaped = arr.reshape(3, 2)<br>
        &nbsp;&nbsp;&nbsp;&nbsp;print(reshaped)  # [[1 2]<br>
                         &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#  [3 4]<br>
                         &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#  [5 6]]<br>
      </p>
      <br>
      <p>
        <b>Маскирование</b> - Маскирование позволяет извлекать или изменять элементы массива, соответствующие определенным условиям.<br><br>
        &nbsp;&nbsp;&nbsp;&nbsparr = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])<br>
        &nbsp;&nbsp;&nbsp;&nbspmask = arr % 2 == 0  <span style="color: rgb(4, 93, 14); font-weight: bold;"># Маска для четных чисел</span><br>
        &nbsp;&nbsp;&nbsp;&nbspprint(arr[mask])  <span style="color: rgb(4, 93, 14); font-weight: bold;"># [2 4 6 8 10]</span><br><br>

        &nbsp;&nbsp;&nbsp;&nbsp<span style="color: rgb(4, 93, 14); font-weight: bold;"># Изменение элементов по маске</span><br>
        &nbsp;&nbsp;&nbsp;&nbsparr[mask] = -1<br>
        &nbsp;&nbsp;&nbsp;&nbspprint(arr)  <span style="color: rgb(4, 93, 14); font-weight: bold;"># [ 1 -1  3 -1  5 -1  7 -1  9 -1]</span>
      </p>
      <p>Также очень много полезных методов: сортировка, максимальное, минимальное, среднее, сумма и многие другие</p>
      <br><br>
      <p>
        <b>Срезы (Slicing) в NumPy</b> - Срезы в NumPy позволяют работать с подмассивами и являются мощным инструментом для обработки данных. Они обеспечивают гибкость и производительность, необходимые для эффективного анализа и манипуляции данными.<br>
        Синтаксис срезов аналогичен срезам в стандартных списках Python и имеет следующий формат: <br>
        <span style="color: rgb(4, 93, 14); font-weight: bold;">arr[start:stop:step]</span><br><br>
        <b>Срезы многомерных массивов</b> - Срезы в многомерных массивах работают аналогично, но позволяют задавать срезы для каждого измерения. (если двумерный - то, отдельно для строк, отдельно для столбцов)
      </p>
    </div>
  </details>

  <!-- 10 -->
  <details class="details">
    <summary class="details__title">Библиотека Numpy. Модуль random.</summary>
    <div class="details__content">
      <p>Модуль random в NumPy предоставляет широкий набор инструментов для генерации случайных чисел, создания массивов случайных чисел и выполнения различных операций, связанных со случайностью. Эти функции являются важным компонентом для научных вычислений, моделирования, статистического анализа и других приложений.</p>
      <p>Функции модуля random могут быть использованы для выполнения различных статистических операций и моделирования. Например, генерация данных для моделирования или тестирования алгоритмов.</p>
      <br>
      <p>Модуль random в NumPy предоставляет мощные инструменты для генерации случайных чисел и выполнения операций, связанных со случайностью. Его использование включает генерацию случайных чисел с различными распределениями, создание массивов случайных чисел, фиксирование начального состояния генератора для воспроизводимости результатов, перемешивание массивов и выборку случайных элементов. Это делает его неотъемлемой частью экосистемы научных вычислений и анализа данных</p><br>
      <br><p><b>Основные функции модуля random (Генерация случайных чисел)</b></p><br>
      <ol>
        <li>
          <b>Случайные числа из равномерного распределения -</b> Функция rand генерирует случайные числа с равномерным распределением в диапазоне от 0 до 1.<br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;random_numbers = np.random.rand(5)<br>
            &nbsp;&nbsp;&nbsp;&nbsp;print(random_numbers)  <b># Пример вывода: [0.69354293 0.82465574 0.54501156 0.43842065 0.82866434]</b>
          </code><br>
        </li>
        <li>
          Можно создавать массивы любой размерности, передавая нужные размеры в качестве аргументов: <br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;random_matrix = np.random.rand(2, 3)<br>
            &nbsp;&nbsp;&nbsp;&nbsp;print(random_matrix)<br>
            &nbsp;&nbsp;&nbsp;&nbsp;<b># Пример вывода:</b><br>
            &nbsp;&nbsp;&nbsp;&nbsp;<b># [[0.27937511 0.71589188 0.79248445]</b><br>
            &nbsp;&nbsp;&nbsp;&nbsp;<b>#  [0.48757711 0.92242775 0.68666152]]</b>
          </code><br>
        </li>
        <li>
          <b>Случайные целые числа -</b> Функция randint генерирует случайные целые числа в заданном диапазоне. <br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;random_integers = np.random.randint(1, 10, size=5) <br>
            &nbsp;&nbsp;&nbsp;&nbsp;print(random_integers)  <b># Пример вывода: [3 6 9 2 7]</b>
          </code>
          <br>
          <p>Размерность массива случайных целых чисел можно задать с помощью параметра size.</p>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;random_integer_matrix = np.random.randint(1, 100, size=(2, 3)) <br>
            &nbsp;&nbsp;&nbsp;&nbsp;print(random_integer_matrix) <br>
            &nbsp;&nbsp;&nbsp;&nbsp;<b># Пример вывода:</b> <br>
            &nbsp;&nbsp;&nbsp;&nbsp;<b># [[54 29 95]</b> <br>
            &nbsp;&nbsp;&nbsp;&nbsp;<b>#  [70 12  5]]</b>
          </code>
        </li>
        <li>
          <p><b>Случайные числа с заданным распределением -</b> Функция uniform генерирует случайные числа с равномерным распределением в заданном диапазоне.</p>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;random_uniform_numbers = np.random.uniform(low=1.0, high=5.0, size=5) <br>
            &nbsp;&nbsp;&nbsp;&nbsp;print(random_uniform_numbers)  <b># Пример вывода: [2.3196554  1.24903198 4.49587546 3.77022684 4.02202499]</b>
          </code>
        </li>
        <li>
          <p><b>Выборка случайных элементов -</b> метод choice достает из нашей последовательности случайное значение</p>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;lst = ['красный', "зеленый", "синий"] <br>
            &nbsp;&nbsp;&nbsp;&nbsp;print('random:', random.choice(lst)) <br>
            &nbsp;&nbsp;&nbsp;&nbsp;print('numpy:', np.random.choice(lst, size=2, replace=False, <span style="color: rebeccapurple;">p=[0.25, 0.05, 0.7]</span>)) <br>
            &nbsp;&nbsp;&nbsp;&nbsp;<b># random: синий</b> <br>
            &nbsp;&nbsp;&nbsp;&nbsp;<b># numpy: ['синий' 'красный']</b>
          </code>
        </li>
      </ol>
    </div>
  </details>

  <!-- 11 -->
  <details class="details">
    <summary class="details__title">Библиотека Matplotlib. Методы .plot(), .bar(), .hist().</summary>
    <div class="details__content">
      <p>Matplotlib — это одна из самых популярных библиотек для визуализации данных в Python. Она позволяет создавать разнообразные графики и диаграммы, обеспечивая широкий набор инструментов для настройки их внешнего вида. В этом ответе мы подробно рассмотрим методы .plot(), .bar(), и .hist().</p>
      <p>Библиотека Matplotlib и её методы .plot(), .bar(), и .hist() предоставляют мощные инструменты для создания разнообразных графиков и диаграмм. Эти методы позволяют визуализировать данные в различных формах, что является важной частью анализа данных. Подробные примеры и возможности настройки позволяют создавать визуализации, соответствующие конкретным потребностям и требованиям анализа.</p>
      <br>
      <ul>
        <li>
          <p><b>Метод .plot()</b> - используется для создания линейных графиков. Он может отображать одномерные массивы данных и их зависимости друг от друга.</p><br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;import matplotlib.pyplot as plt <br>
            &nbsp;&nbsp;&nbsp;&nbsp;import numpy as np <br><br>
            &nbsp;&nbsp;&nbsp;&nbsp;<b># Создание данных</b><br>
            &nbsp;&nbsp;&nbsp;&nbsp;x = np.linspace(0, 10, 100)<br>
            &nbsp;&nbsp;&nbsp;&nbsp;y = np.sin(x) <br><br>

            &nbsp;&nbsp;&nbsp;&nbsp;<b># Построение графика</b><br>
            &nbsp;&nbsp;&nbsp;&nbsp;plt.plot(x, y)<br>
            &nbsp;&nbsp;&nbsp;&nbsp;plt.title('Simple Line Plot')<br>
            &nbsp;&nbsp;&nbsp;&nbsp;plt.xlabel('x')<br>
            &nbsp;&nbsp;&nbsp;&nbsp;plt.ylabel('sin(x)')<br>
            &nbsp;&nbsp;&nbsp;&nbsp;plt.show()
          </code>
          <br><br>
          <p><b>Метод .plot() поддерживает множество параметров для настройки внешнего вида графика.</b></p><br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;<b># Построение графика с настройками</b> <br>
            &nbsp;&nbsp;&nbsp;&nbsp;plt.plot(x, y, label='sin(x)', color='blue', linestyle='--', linewidth=2, marker='o') <br>
            &nbsp;&nbsp;&nbsp;&nbsp;plt.title('Styled Line Plot') <br>
            &nbsp;&nbsp;&nbsp;&nbsp;plt.xlabel('x') <br>
            &nbsp;&nbsp;&nbsp;&nbsp;plt.ylabel('sin(x)') <br>
            &nbsp;&nbsp;&nbsp;&nbsp;plt.legend() <br>
            &nbsp;&nbsp;&nbsp;&nbsp;plt.grid(True) <br>
            &nbsp;&nbsp;&nbsp;&nbsp;plt.show()
          </code>
          <br><br>
        </li>
        <li>
          <p><b>Метод .bar()</b> - Метод .bar() используется для построения столбчатых диаграмм, которые представляют данные в виде прямоугольников, где длина каждого прямоугольника пропорциональна значению.</p>
          <br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;<b># Создание данных</b><br>
            &nbsp;&nbsp;&nbsp;&nbsp;categories = ['A', 'B', 'C', 'D']<br>
            &nbsp;&nbsp;&nbsp;&nbsp;values = [3, 7, 5, 9]<br>
            <br>
            &nbsp;&nbsp;&nbsp;&nbsp;<b># Построение столбчатой диаграммы</b><br>
            &nbsp;&nbsp;&nbsp;&nbsp;plt.bar(categories, values)<br>
            &nbsp;&nbsp;&nbsp;&nbsp;plt.title('Simple Bar Plot')<br>
            &nbsp;&nbsp;&nbsp;&nbsp;plt.xlabel('Categories')<br>
            &nbsp;&nbsp;&nbsp;&nbsp;plt.ylabel('Values')<br>
            &nbsp;&nbsp;&nbsp;&nbsp;plt.show()
          </code>
          <br><br>
          <p><b>Сгруппированные и сложенные столбчатые диаграммы</b> - Для создания более сложных столбчатых диаграмм, таких как сгруппированные и сложенные, используются дополнительные настройки.</p>
          <ol>
            <li>
              Сгруппированная столбчатая диаграмма<br><br>
              <code>
                &nbsp;&nbsp;&nbsp;&nbsp;<b># Создание данных</b><br>
                &nbsp;&nbsp;&nbsp;&nbsp;bar_width = 0.35 <br>
                &nbsp;&nbsp;&nbsp;&nbsp;index = np.arange(len(categories)) <br>
                &nbsp;&nbsp;&nbsp;&nbsp;values2 = [2, 6, 4, 8] <br>
                <br>              
                &nbsp;&nbsp;&nbsp;&nbsp;<b># Построение сгруппированной столбчатой диаграммы </b><br>
                &nbsp;&nbsp;&nbsp;&nbsp;plt.bar(index, values, bar_width, label='Group 1', color='b') <br>
                &nbsp;&nbsp;&nbsp;&nbsp;plt.bar(index + bar_width, values2, bar_width, label='Group 2', color='r') <br>
                &nbsp;&nbsp;&nbsp;&nbsp;plt.xlabel('Categories') <br>
                &nbsp;&nbsp;&nbsp;&nbsp;plt.ylabel('Values') <br>
                &nbsp;&nbsp;&nbsp;&nbsp;plt.title('Grouped Bar Plot') <br>
                &nbsp;&nbsp;&nbsp;&nbsp;plt.xticks(index + bar_width / 2, categories) <br>
                &nbsp;&nbsp;&nbsp;&nbsp;plt.legend() <br>
                &nbsp;&nbsp;&nbsp;&nbsp;plt.show()
              </code><br><br>
            </li>
            <li>
              Сложенная столбчатая диаграмма <br><br>
              <code>
                &nbsp;&nbsp;&nbsp;&nbsp;<b># Построение сложенной столбчатой диаграммы</b><br>
                &nbsp;&nbsp;&nbsp;&nbsp;plt.bar(categories, values, label='Group 1', color='b') <br>
                &nbsp;&nbsp;&nbsp;&nbsp;plt.bar(categories, values2, bottom=values, label='Group 2', color='r') <br>
                &nbsp;&nbsp;&nbsp;&nbsp;plt.xlabel('Categories') <br>
                &nbsp;&nbsp;&nbsp;&nbsp;plt.ylabel('Values') <br>
                &nbsp;&nbsp;&nbsp;&nbsp;plt.title('Stacked Bar Plot') <br>
                &nbsp;&nbsp;&nbsp;&nbsp;plt.legend() <br>
                &nbsp;&nbsp;&nbsp;&nbsp;plt.show()
              </code>
            </li>
          </ol><br><br>
        </li>
        <li>
          <p><b>Метод .hist()</b> - Метод .hist() используется для создания гистограмм, которые отображают распределение данных. Гистограмма разбивает данные на интервалы (бинсы) и показывает количество данных в каждом интервале.</p>
          <br>
          <p>Аргументы и параметры</p>
              <ol>
                <li>
                  data <br>
                  Описание: Массив числовых данных, который будет использоваться для построения гистограммы. Тип: array-like (например, список, массив NumPy и т.д.)
                </li>
                <li>
                  bins <br>
                  Количество интервалов (бинсов), на которые будут разделены данные. Бинсы определяют, как данные будут группироваться. Тип: int или sequence
                </li>
                <li>
                  density <br>
                  Описание: Если True, то гистограмма будет нормализована так, что площадь под гистограммой будет равна 1 (показывает плотность вероятности). Тип: bool
                </li>
                <li>
                  color <br>
                  Описание: Цвет прямоугольников гистограммы. Тип: str или sequence
                </li>
                <li>
                  edgecolor <br>
                  Описание: Цвет границ прямоугольников. Тип: str или sequence
                </li>
                <li>
                  alpha <br>
                  Описание: Прозрачность прямоугольников гистограммы. Значение должно быть в диапазоне от 0 (полностью прозрачный) до 1 (полностью непрозрачный). Тип: float
                </li>
              </ol>
        </li>
      </ul>
    </div>
  </details>

  <!-- 12 -->
  <details class="details">
    <summary class="details__title">Модули. Модуль os.</summary>
    <div class="details__content">
      <p><b>Модуль</b> — это файл, содержащий код на Python, который может включать определения функций, классов и переменных. Модули позволяют структурировать программу, разделяя код на логические части, которые могут быть многократно использованы в разных программах.</p>
      <br>
      <p>Модули и пакеты являются важными компонентами Python, позволяющими организовывать и многократно использовать код. Модуль os предоставляет множество полезных функций для взаимодействия с операционной системой, что делает его незаменимым инструментом для выполнения различных системных операций. Понимание и умение работать с модулями и модулем os позволяет создавать более гибкие и мощные программы.</p>
      <br>
      <ul><b>Зачем нужны модули?</b>
        <li><b>Организация кода:</b> Разделение большого кода на более мелкие и понятные части.</li>
        <li><b>Повторное использование:</b> Код, написанный в одном модуле, может быть импортирован и использован в других программах или модулях.</li>
        <li><b>Изоляция:</b> Модули позволяют изолировать код, чтобы избежать конфликтов имен переменных и функций.</li>
        <li><b>Упрощение тестирования и отладки:</b> Меньшие и более изолированные части кода легче тестировать и отлаживать.</li>
      </ul>
      <br><p><b>Чтобы использовать функции, классы или переменные из модуля, его нужно импортировать в другой файл</b></p>
      <br><p>Пакет — это коллекция модулей, организованная в директории, которая содержит файл __init__.py. Пакеты позволяют создавать многоуровневую структуру модулей.</p>
      <br><p><b>Модуль os</b></p>
      <p>Модуль os в Python предоставляет функции для взаимодействия с операционной системой. Он позволяет выполнять операции, такие как управление файлами и директориями, работа с путями, получение информации о системе и многого другого.</p>
      <br>
      <ol>Основные функции модуля os
        <li>
          Работа с текущей директорией
          <ul>
            <li><b>os.getcwd():</b> Возвращает текущую рабочую директорию.</li>
            <li><b>os.chdir(path):</b> Меняет текущую рабочую директорию</li>
          </ul>
        </li>
        <li>
          Работа с файлами и директориями
          <ul>
            <li><b>os.listdir(path='.'):</b> Возвращает список файлов и директорий в указанной директории.</li>
            <li><b>os.mkdir(path):</b> Создает новую директорию</li>
            <li><b>os.makedirs(path):</b> Создает директорию и все промежуточные директории</li>
            <li><b>os.remove(path):</b> Удаляет файл.</li>
            <li><b>os.rmdir(path):</b> Удаляет пустую директорию.</li>
            <li><b>os.removedirs(path):</b> Удаляет директорию и все промежуточные пустые директории.</li>
          </ul>
        </li>
        <li>
          Работа с путями
          <ul>
            <li><b>os.path.join(path, *paths):</b> Соединяет один или несколько компонентов пути.</li>
            <li><b>os.path.exists(path):</b> Проверяет, существует ли указанный путь.</li>
            <li><b>os.path.isfile(path):</b> Проверяет, является ли указанный путь файлом.</li>
            <li><b>os.path.isdir(path):</b> Проверяет, является ли указанный путь директорией.</li>
            <li><b>os.path.basename(path):</b> Возвращает базовое имя пути.</li>
            <li><b>os.path.dirname(path):</b> Возвращает имя директории пути.</li>
            <li><b>os.path.abspath(path):</b> Возвращает абсолютный путь.</li>
          </ul>
        </li>
        <li>
          Получение информации о системе
          <ul>
            <li><b>os.name:</b> Имя операционной системы.</li>
            <li><b>os.environ:</b> Словарь переменных окружения.</li>
            <li><b>os.getlogin():</b> Имя текущего пользователя.</li>
            <li><b>os.getpid():</b> ID текущего процесса.</li>
          </ul>
        </li>
        <li>
          Выполнение системных команд
          <ul>
            <li><b>os.system(command):</b> Выполняет команду в оболочке операционной системы.</li>
          </ul>
        </li>
        <li>
          Работа с процессами
          <ul>
            <li><b>os.fork():</b> Создает новый процесс (только для Unix).</li>
            <li><b>os.execv(path, args):</b> Заменяет текущий процесс новым.</li>
            <li><b>os._exit(status):</b> Завершает текущий процесс.</li>
          </ul>
        </li>
      </ol>
    </div>
  </details>

  <!-- 13 -->
  <details class="details">
    <summary class="details__title">Работа с файлами. Функция open(). Контекстный менеджер with.</summary>
    <div class="details__content">
      <p>Работа с файлами — это одна из ключевых задач в программировании. Python предоставляет удобные инструменты для чтения и записи файлов, а также для управления их контекстом. Основными инструментами для этого являются функция open() и контекстный менеджер with.</p>
      <br><p>Работа с файлами является важным аспектом программирования на Python. Использование функции open() в сочетании с контекстным менеджером with обеспечивает надежное и эффективное управление файлами. Контекстный менеджер автоматически заботится о закрытии файлов, что уменьшает риск утечек ресурсов и улучшает читаемость кода. Понимание различных режимов открытия файлов и возможностей управления ими позволяет создавать более гибкие и мощные программы.</p>
      <br><p><b>Функция open()</b> - Функция open() используется для открытия файлов. Она возвращает объект файла, который может быть использован для чтения, записи или других операций. Формат вызова функции open() выглядит следующим образом:</p>
      <code>
        open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)
      </code>
      <br><br>
      <ul><b>Основные параметры функции open()</b>
        <li><b>file:</b> Имя файла, который необходимо открыть. Это обязательный параметр.</li>
        <li>
          <b>mode:</b> Режим открытия файла. По умолчанию 'r' (чтение). <b>Варианты:</b>
          <ul>
            <li><b>'r'</b> – чтение (по умолчанию)</li>
            <li><b>'w'</b> – запись (создает новый файл или очищает существующий)</li>
            <li><b>'a'</b> – добавление (добавляет данные в конец файла)</li>
            <li><b>'b'</b> – бинарный режим (например, 'rb' для чтения в бинарном режиме)</li>
            <li><b>'t'</b> – текстовый режим (по умолчанию, например, 'rt' для чтения в текстовом режиме)</li>
            <li><b>'+'</b> – чтение и запись (например, 'r+' для чтения и записи)</li>
          </ul>
        </li>
      </ul>
      <br><br>
      <p><b>Контекстный менеджер with</b> - Контекстный менеджер with предоставляет удобный способ работы с файлами, обеспечивая автоматическое закрытие файла после завершения блока with. Это помогает избежать утечек ресурсов и ошибок, связанных с незакрытыми файлами.</p>
      <br>
      <p><b>Основная структура использования контекстного менеджера with</b></p>
      <code>
        &nbsp;&nbsp;&nbsp;&nbsp;with open('filename', 'mode') as file: <br>
        &nbsp;&nbsp;&nbsp;&nbsp;<b># Операции с файлом</b> <br>
        &nbsp;&nbsp;&nbsp;&nbsp;pass
      </code>
      <br><br>
      <ol><b>Преимущества использования контекстного менеджера with</b>
        <li><b>Автоматическое закрытие файлов:</b> Файл автоматически закрывается по завершении блока with, что уменьшает риск утечки ресурсов.</li>
        <li><b>Обработка исключений:</b> В случае возникновения исключения файл все равно будет корректно закрыт.</li>
        <li><b>Более чистый и читаемый код:</b> Уменьшается необходимость явного вызова метода close().</li>
      </ol>
    </div>
  </details>

  <!-- 14 -->
  <details class="details">
    <summary class="details__title">Библиотека Pandas. Базовые методы.</summary>
    <div class="details__content">
      <p><b>Pandas</b> — это мощная и широко используемая библиотека Python для анализа данных. Она предоставляет высокоуровневые структуры данных и функции, предназначенные для упрощения работы с метко-ориентированными данными, включая табличные данные, временные ряды и другие формы данных</p>
      <br>
      <ol><b>Основные структуры данных Pandas</b>
        <li><b>Series:</b> Одномерный массив, который может содержать любые данные (интегрированные с индексами).</li>
        <li><b>DataFrame:</b> Двумерная таблица с метками строк и столбцов, представляющая собой наиболее часто используемую структуру данных в Pandas.</li>
      </ol>
      <br>
      <p><b>Базовые методы Pandas</b></p><br>
      <ol><b>Методы для работы с DataFrame</b>
        <li>
          <b>Чтение данных</b>
          <ul>
            <li>pd.read_csv(): Чтение данных из CSV файла.</li>
            <li>pd.read_excel(): Чтение данных из Excel файла.</li>
            <li>pd.read_json(): Чтение данных из JSON файла.</li>
          </ul>
        </li>
        <li>
          <b>Запись данных</b>
          <ul>
            <li>df.to_csv(): Запись DataFrame в CSV файл.</li>
            <li>df.to_excel(): Запись DataFrame в Excel файл.</li>
            <li>df.to_json(): Запись DataFrame в JSON файл.</li>
          </ul>
        </li>
        <li>
          <b>Информация о DataFrame</b>
          <ul>
            <li>df.head(n): Возвращает первые n строк DataFrame.</li>
            <li>df.tail(n): Возвращает последние n строк DataFrame.</li>
            <li>df.info(): Отображает краткую информацию о DataFrame, включая индекс, тип данных и ненулевые значения.</li>
            <li>df.describe(): Выводит основные статистические характеристики DataFrame.</li>
          </ul>
        </li>
        <li>
          <b>Индексация и фильтрация</b>
          <ul>
            <li>Индексация по метке <br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(df['Name'])  # Возвращает Series <br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(df[['Name', 'Age']])  # Возвращает DataFrame
            </li>
            <li>Логическая индексация <br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;adults = df[df['Age'] > 30]
            </li>
            <li>Локатор по метке <br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(df.loc[0])  # Первая строка DataFrame <br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(df.loc[:, 'Name'])  # Все строки столбца 'Name'
            </li>
            <li>Локатор по позиции <br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(df.iloc[0])  # Первая строка DataFrame <br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(df.iloc[:, 0])  # Все строки первого столбца
            </li>
          </ul>
        </li>
        <li>
          <b>Добавление и удаление данных</b>
          <ul>
            <li>Добавление нового столбца <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;df['Salary'] = [50000, 60000, 70000]</li>
            <li>Удаление столбца <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;df.drop('Salary', axis=1, inplace=True)</li>
            <li>Удаление строки <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;df.drop(1, axis=0, inplace=True)  # Удаляет вторую строку</li>
          </ul>
        </li>
        <li>
          <b>Обработка отсутствующих данных</b>
          <ul>
            <li>Проверка наличия пропущенных данных <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;df.isna()</li>
            <li>Удаление пропущенных данных <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;df.dropna(inplace=True)</li>
            <li>Заполнение пропущенных данных <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;df.fillna(0, inplace=True)</li>
          </ul>
        </li>
        <li>
          <b>Группировка данных</b>
          <ul>
            <li>Группировка и агрегирование <br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;grouped = df.groupby('City') <br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(grouped['Age'].mean())  # Средний возраст по городам
            </li>
          </ul>
        </li>
        <br><br>
        <ol><b><h3>Методы для работы с Series</h3></b>
          <li>
            <b>Базовые операции</b>
            <ul>
              <li>Получение значения по индексу <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(s[0])  # Первое значение</li>
              <li>Фильтрация <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(s[s > 2])  # Все значения больше 2</li>
              <li>Операции с индексами <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;s.index = ['a', 'b', 'c', 'd', 'e']</li>
            </ul>
          </li>
          <li>
            <b>Статистические методы</b>
            <ul>
              <li>
                Основные статистические характеристики <br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(s.mean())  # Среднее значение <br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(s.sum())  # Сумма всех значений <br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(s.max())  # Максимальное значение <br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(s.min())  # Минимальное значение <br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(s.std())  # Стандартное отклонение
              </li>
            </ul>
          </li>
        </ol>
      </ol>
    </div>
  </details>

  <!-- 15 -->
  <details class="details">
    <summary class="details__title">Библиотека Pandas. Статистические методы.</summary>
    <div class="details__content">
      <p>Pandas — это мощная библиотека для анализа данных на языке Python, которая включает в себя множество встроенных методов для вычисления статистических характеристик. Эти методы позволяют быстро и эффективно анализировать и обрабатывать данные.</p>
      <br><p><b>Основные статистические методы Pandas</b></p>
      <p>Большинство статистических методов можно применять как к Series, так и к DataFrame. При применении к DataFrame методы по умолчанию вычисляют статистику по столбцам, но можно изменить поведение с помощью параметра axis.</p>
      <br><br>
      <ol><b>Часто используемые статистические методы</b>
        <li>Метод count() - Возвращает количество ненулевых значений в каждом столбце (или строке, если axis=1).</li>
        <li>Метод sum() - Возвращает сумму значений по каждому столбцу (или строке, если axis=1).</li>
        <li>Метод mean() - Возвращает среднее значение по каждому столбцу (или строке, если axis=1).</li>
        <li>Метод median() - Возвращает медиану значений по каждому столбцу (или строке, если axis=1).</li>
        <li>Метод std() - Возвращает стандартное отклонение значений по каждому столбцу (или строке, если axis=1).</li>
        <li>Метод var() - Возвращает дисперсию значений по каждому столбцу (или строке, если axis=1).</li>
        <li>Метод min() - Возвращает минимальное значение по каждому столбцу (или строке, если axis=1).</li>
        <li>Метод max() - Возвращает максимальное значение по каждому столбцу (или строке, если axis=1).</li>
        <li>Метод idxmin() - Возвращает индекс минимального значения по каждому столбцу (или строке, если axis=1).</li>
        <li>Метод idxmax() - Возвращает индекс максимального значения по каждому столбцу (или строке, если axis=1).</li>
        <li>Метод describe() - Возвращает основные статистические характеристики DataFrame или Series: количество ненулевых значений, среднее, стандартное отклонение, минимум, 25-й перцентиль, медиана, 75-й перцентиль и максимум.</li>
        <li>Метод corr() - Возвращает коэффициент корреляции Пирсона между столбцами DataFrame.</li>
        <li>Метод cov() - Возвращает ковариацию между столбцами DataFrame.</li>
      </ol>
    </div>
  </details>

  <!-- 16 -->
  <details class="details">
    <summary class="details__title">Генераторы списков.</summary>
    <div class="details__content">
      <p>Генераторы списков (list comprehensions) в Python предоставляют удобный и элегантный способ создания списков. Они позволяют создавать новые списки, применяя выражение к каждому элементу последовательности (например, списка или диапазона) и могут включать условные выражения для фильтрации элементов.</p>
      <br>
      <code>[expression for item in iterable if condition]</code><br><br>
      <ul><b>Базовый синтаксис генератора списков выглядит следующим образом:</b>
        <li><b>expression:</b> Выражение, применяемое к каждому элементу.</li>
        <li><b>item:</b> Переменная, представляющая текущий элемент из последовательности.</li>
        <li><b>iterable:</b> Последовательность (например, список или диапазон), по которой происходит итерация.</li>
        <li><b>condition:</b> (необязательно) Условие для фильтрации элементов.</li>
      </ul>
      <br>
      <ol><b>Преимущества генераторов списков</b>
        <li>
          <b>Краткость и читабельность:</b> Генераторы списков позволяют создавать списки в одну строку, делая код более компактным и понятным.
        </li>
        <li>
          <b>Производительность:</b> Генераторы списков часто работают быстрее, чем эквивалентные конструкции с использованием циклов.
        </li>
        <li>
          <b>Функциональность:</b> Возможность включать выражения и условия в генераторы списков делает их мощным инструментом для обработки данных.
        </li>
      </ol>
      <br>
      <ol><b>Примеры использования генераторов списков</b>
        <li>
          <b>Создание списка квадратов чисел</b><br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;squares = [x**2 for x in range(10)] <br>
            &nbsp;&nbsp;&nbsp;&nbsp;print(squares) <br>
            &nbsp;&nbsp;&nbsp;&nbsp;# Вывод: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]
          </code>
        </li>
        <li>
          <b>Создание списка четных чисел</b><br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;evens = [x for x in range(20) if x % 2 == 0] <br>
            &nbsp;&nbsp;&nbsp;&nbsp;print(evens) <br>
            &nbsp;&nbsp;&nbsp;&nbsp;# Вывод: [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]
          </code>
        </li>
        <li>
          <b>Преобразование строки в список символов</b><br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;chars = [char for char in "hello"] <br>
            &nbsp;&nbsp;&nbsp;&nbsp;print(chars) <br>
            &nbsp;&nbsp;&nbsp;&nbsp;# Вывод: ['h', 'e', 'l', 'l', 'o']
          </code>
        </li>
        <li>
          <b>Создание списка пар (число, его квадрат)</b><br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;pairs = [(x, x**2) for x in range(10)] <br>
            &nbsp;&nbsp;&nbsp;&nbsp;print(pairs) <br>
            &nbsp;&nbsp;&nbsp;&nbsp;# Вывод: [(0, 0), (1, 1), (2, 4), (3, 9), (4, 16), (5, 25), (6, 36), (7, 49), (8, 64), (9, 81)]
          </code>
        </li>
        <li>
          <b>Использование вложенных циклов в генераторах списков</b><br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;matrix = [[i * j for j in range(5)] for i in range(5)] <br>
            &nbsp;&nbsp;&nbsp;&nbsp;print(matrix) <br>
            &nbsp;&nbsp;&nbsp;&nbsp;# Вывод: [[0, 0, 0, 0, 0], [0, 1, 2, 3, 4], [0, 2, 4, 6, 8], [0, 3, 6, 9, 12], [0, 4, 8, 12, 16]]
          </code>
        </li>
      </ol>
    </div>
  </details>

  <h2><strong>Нейронные сети</strong></h2>

  <!-- 1 -->
  <details class="details">
    <summary class="details__title">Fast API. Создание и запуск приложения с помощью данного фреймворка</summary>
    <div class="details__content">
      <p>FastAPI — это современный, высокопроизводительный веб-фреймворк для создания API с Python 3.6+ на основе стандартов OpenAPI и JSON Schema. Он разработан для быстрого написания кода и создания API, которые могут работать с высокой скоростью и эффективностью.</p>
      <br>
      <ol><b>Основные преимущества FastAPI:</b>
        <li><b>Высокая производительность:</b> Сравнима с производительностью NodeJS и Go (благодаря Starlette и Pydantic).</li>
        <li><b>Автоматическая документация:</b> Генерирует интерактивную документацию для API с помощью Swagger UI и ReDoc.</li>
        <li><b>Типизация: </b>Полная поддержка аннотаций типов Python, что помогает в создании надежного и проверенного кода</li>
        <li><b>Простота использования:</b> Быстрое и простое создание API.</li>
      </ol>
      <br>
      <ol><b>Создание базового приложения</b>
        <li>
          Для начала необходимо установить FastAPI и Uvicorn, ASGI сервер для запуска приложения: <b><code>pip install fastapi "uvicorn[standard]"</code></b>
        </li>
        <li>
          Импорт необходимых модулей: <b><code>from fastapi import FastAPI</code></b>
        </li>
        <li>
          Создание экземпляра FastAPI: <b><code>app = FastAPI()</code></b>
        </li>
        <li>
          Определение маршрутов (endpoints) <br>
          Маршруты определяются с помощью декораторов. Декораторы указывают, какой HTTP метод используется для маршрута (GET, POST, PUT, DELETE и т.д.) и путь к маршруту. <br><br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;<span style="color: orange">@app.get("/")</span><br>
            &nbsp;&nbsp;&nbsp;&nbsp;def read_root(): <br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return {"Hello": "World"} <br>
          </code><br><p>Этот код создает простой маршрут, который возвращает JSON-объект {"Hello": "World"} при обращении к корневому URL (/).</p>
        </li>
        <li>
          Запуск приложения осуществляется с помощью Uvicorn: <b><code>uvicorn main:app --reload --port 8000 --host 0.0.0.0 &</code></b><br>
          <p>Здесь main — это имя файла Python (без .py), app — это экземпляр FastAPI, а --reload включает режим перезагрузки, чтобы изменения в коде автоматически обновлялись.</p>
        </li>
      </ol>
      <br><br><p><b>Пример: Создание более сложного API</b></p><br>
      <ol>
        <li>
          <b>Определение маршрутов с параметрами</b> <br><br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;from typing import Optional <br>
            <br>
            &nbsp;&nbsp;&nbsp;&nbsp;@app.get("/items/{item_id}") <br>
            &nbsp;&nbsp;&nbsp;&nbsp;def read_item(item_id: int, q: Optional[str] = None): <br>
               &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return {"item_id": item_id, "q": q}
          </code>
          <br><br><p>Этот маршрут принимает путь параметра item_id и необязательный параметр запроса q.</p><br>
        </li>
        <li>
          <b>Обработка POST-запросов с телом запроса</b> (Для обработки данных в теле запроса мы используем Pydantic модели.) <br><br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;from pydantic import BaseModel <br>
            <br>
            &nbsp;&nbsp;&nbsp;&nbsp;class Item(BaseModel): <br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;name: str <br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;description: Optional[str] = None <br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;price: float <br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tax: Optional[float] = None <br>
            <br>
            &nbsp;&nbsp;&nbsp;&nbsp;@app.post("/items/") <br>
            &nbsp;&nbsp;&nbsp;&nbsp;def create_item(item: Item): <br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return item
          </code>
          <br><br><p>Здесь мы определяем Pydantic модель Item и используем её в маршруте для обработки POST-запроса.</p><br>
        </li>
      </ol>
      <br>
      <ol><b>Работа с запросами и ответами</b>
        <li>
          <b>Параметры пути и запроса</b> - FastAPI автоматически парсит параметры пути и запросов и проверяет их типы. <br><br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;@app.get("/users/{user_id}") <br>
            &nbsp;&nbsp;&nbsp;&nbsp;def read_user(user_id: int, name: Optional[str] = None): <br>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return {"user_id": user_id, "name": name}
          </code><br><br>
        </li>
        <li>
          <b>Валидация и обработка данных</b> - Использование Pydantic моделей обеспечивает валидацию данных и автоматическую документацию<br><br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;class User(BaseModel): <br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;username: str <br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;email: str <br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;age: Optional[int] = None <br>
            <br>
            &nbsp;&nbsp;&nbsp;&nbsp;@app.post("/users/") <br>
            &nbsp;&nbsp;&nbsp;&nbsp;def create_user(user: User): <br>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return user
          </code>
        </li>
      </ol>
      <br>
      <ol><b>Автоматическая документация</b> - FastAPI автоматически генерирует документацию для всех маршрутов. Вы можете получить доступ к ней по следующим URL:
        <li>Swagger UI: <b><code>http://127.0.0.1:8000/docs</code></b></li>
        <li>ReDoc: <b><code>http://127.0.0.1:8000/redoc</code></b></li>
      </ol><br><br>
      <p><b>Асинхронное программирование -</b> FastAPI поддерживает асинхронное программирование с помощью async def.</p>
      <br>
      <code>
        &nbsp;&nbsp;&nbsp;&nbsp;import asyncio <br>
        <br>
        &nbsp;&nbsp;&nbsp;&nbsp;@app.get("/async") <br>
        &nbsp;&nbsp;&nbsp;&nbsp;async def get_async(): <br>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;await asyncio.sleep(1) <br>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return {"message": "Hello, async world!"}
      </code><br><br>
      <p>FastAPI — мощный инструмент для создания API с Python, который обеспечивает высокую производительность и удобство использования. Он предлагает множество возможностей для работы с запросами, ответами, асинхронным программированием, а также предоставляет автоматическую документацию и валидацию данных с помощью Pydantic. Быстрый старт с FastAPI позволяет разработчикам быстро и эффективно создавать API, сохраняя при этом высокие стандарты качества и производительности.</p>
    </div>
  </details>

  <!-- 2 -->
  <details class="details">
    <summary class="details__title">Активационные функции.</summary>
    <div class="details__content">
      <p>Активационные функции играют ключевую роль в работе нейронных сетей, определяя, как сигналы нейронов передаются дальше в сеть. Они вводят нелинейность в модель, что позволяет нейронным сетям решать сложные задачи, которые не могут быть решены линейными моделями.</p>
      <p>Можно сказать, что это ключевой компонент нейронных сетей, который позволяет моделям решать нелинейные задачи. Понимание их свойств и влияние на процесс обучения помогает выбирать правильные функции для конкретных задач и оптимизировать работу нейронных сетей.</p>
      <br>
      <ol><b>Основные активационные функции</b>
        <li>
          <b>Линейная активационная функция (Linear Activation Function)</b><br>
          Функция просто возвращает входное значение без изменений: <b>f(x)=x</b>
          <ul>
            <li><b>Преимущества:</b> Простота.</li>
            <li><b>Недостатки:</b> Не вводит нелинейности, что ограничивает возможности модели.</li>
          </ul>
        </li>
        <li>
          <b>Функция сигмоиды (Sigmoid Activation Function)</b><br>
          Сигмоидальная функция (логистическая функция) сжимает входные значения в диапазон от 0 до 1
          <ul>
            <li><b>Преимущества:</b> Используется для моделирования вероятностей.</li>
            <li><b>Недостатки:</b> Может вызывать проблему исчезающего градиента, замедляя обучение глубоких сетей.</li>
          </ul>
        </li>
        <li>
          <b>Гиперболический тангенс (Hyperbolic Tangent, Tanh)</b><br>
          Функция тангенса сжимает значения в диапазон от -1 до 1
          <ul>
            <li><b>Преимущества:</b> Значения центрированы вокруг нуля, что может ускорить обучение.</li>
            <li><b>Недостатки:</b> Также подвержена проблеме исчезающего градиента.</li>
          </ul>
        </li>
        <li>
          <b>Прямолинейная активационная функция (Rectified Linear Unit, ReLU)</b><br>
          Функция ReLU устанавливает все отрицательные значения на ноль, а положительные значения оставляет без изменений
          <ul>
            <li><b>Преимущества:</b> Простота и эффективность, решает проблему исчезающего градиента.</li>
            <li><b>Недостатки:</b> Может возникать проблема «мертвых» нейронов, когда градиент равен нулю для отрицательных входных значений.</li>
          </ul>
        </li>
        <li>
          <b>Леченная ReLU (Leaky ReLU)</b><br>
          Модификация ReLU, которая позволяет небольшое отрицательное значение для отрицательных входов
          <ul>
            <li><b>Преимущества:</b> Снижает вероятность возникновения «мертвых» нейронов.</li>
            <li><b>Недостатки:</b> Несколько сложнее, чем обычная ReLU.</li>
          </ul>
        </li>
        <li>
          <b>Функция ELU (Exponential Linear Unit)</b><br>
          Функция ELU похожа на ReLU, но для отрицательных значений применяет экспоненциальное преобразование:
          <ul>
            <li><b>Преимущества:</b> Уменьшает смещение, поддерживает положительные значения.</li>
            <li><b>Недостатки:</b> Более сложная функция.</li>
          </ul>
        </li>
        <li>
          <b>Функция Softmax</b><br>
          Функция Softmax используется в выходном слое классификационных моделей для многоклассовых задач. Она преобразует вектор входных значений в вероятности:
          <ul>
            <li><b>Преимущества:</b> Позволяет моделировать многоклассовую классификацию.</li>
            <li><b>Недостатки:</b> Затрудняет обучение при больших значениях.</li>
          </ul>
        </li>
      </ol>
      <br><br>
      <ol><b>Влияние активационных функций на обучение</b>
        <li>
          <b>Нелинейность</b> - Основная роль активационных функций — введение нелинейности. Без этого нейронные сети будут работать как линейные модели, неспособные моделировать сложные зависимости в данных.
        </li>
        <li>
          <b>Градиенты и обучение</b> - Активационные функции влияют на процесс обучения через обратное распространение. Проблема исчезающего и взрывающегося градиента связана с выбором активационных функций. Например, сигмоид и tanh могут сильно уменьшить градиенты, замедляя обучение.
        </li>
      </ol>
      <br><br>
      <ol><b>Выбор активационной функции</b><br>Выбор активационной функции зависит от конкретной задачи и структуры модели. В практике чаще всего используются следующие комбинации:
        <li>
          <b>Внутренние слои:</b> ReLU или её вариации (Leaky ReLU, ELU) из-за их эффективности и способности решать проблему исчезающего градиента.
        </li>
        <li>
          <b>Выходные слои для классификации:</b>
          <ul>
            <li><b>Двухклассовая классификация:</b> Сигмоида.</li>
            <li><b>Многоклассовая классификация:</b> Softmax.</li>
          </ul>
        </li>
        <li>
          <b>Выходные слои для регрессии:</b> Линейная активационная функция.
        </li>
      </ol>
    </div>
  </details>

  <!-- 3 -->
  <details class="details">
    <summary class="details__title">Функция ошибки. Стандартные функции ошибок keras.</summary>
    <div class="details__content">
      <p>Функция ошибки, или функция потерь, играет ключевую роль в обучении моделей машинного обучения и нейронных сетей. Она измеряет, насколько хорошо или плохо модель делает свои прогнозы, предоставляя метрику для оптимизации модели во время обучения. Цель обучения заключается в минимизации функции потерь, что означает улучшение точности прогнозов модели.</p>
      <br>
      <ol><b>Основные функции ошибок</b>
        <li>
          <b>Среднеквадратичная ошибка (Mean Squared Error, MSE)</b><br>
          Среднеквадратичная ошибка — это наиболее часто используемая функция потерь для задач регрессии. Она измеряет среднее значение квадратов ошибок между прогнозируемыми и истинными значениями:
          <ul>
            <li>Преимущества: Простота вычисления и интерпретации.</li>
            <li>Недостатки: Чувствительность к выбросам, поскольку квадратичные ошибки увеличиваются экспоненциально.</li>
          </ul>
        </li>
        <li>
          <b>Средняя абсолютная ошибка (Mean Absolute Error, MAE)</b><br>
          Средняя абсолютная ошибка измеряет среднее значение абсолютных ошибок между прогнозируемыми и истинными значениями:
          <ul>
            <li>Преимущества: Менее чувствительна к выбросам по сравнению с MSE</li>
            <li>Недостатки: Меньше наказывает за большие ошибки, чем MSE.</li>
          </ul>
        </li>
        <li>
          <b>Кросс-энтропия (Cross-Entropy)</b><br>
          Кросс-энтропия используется для задач классификации. Она измеряет разницу между двумя вероятностными распределениями: истинным распределением и прогнозируемым распределением модели.
          <ul>
            <li>Бинарная кросс-энтропия (Binary Cross-Entropy): Используется для двоичной классификации.</li>
            <li>Категориальная кросс-энтропия (Categorical Cross-Entropy): Используется для многоклассовой классификации.</li>
          </ul>
        </li>
        <li>
          <b>Hinge Loss</b><br>
          Hinge Loss используется для задач классификации, особенно в методе опорных векторов (SVM): <br>
          набор схожих алгоритмов обучения с учителем, использующихся для задач классификации и регрессионного анализа. Принадлежит семейству линейных классификаторов и может также рассматриваться как частный случай регуляризации по Тихонову. Особым свойством метода опорных векторов является непрерывное уменьшение эмпирической ошибки классификации и увеличение зазора, поэтому метод также известен как метод классификатора с максимальным зазором.
        </li>
      </ol><br>
      <ol><b>Функции ошибок в Keras</b><br>Keras предоставляет набор стандартных функций потерь, которые можно легко использовать при определении модели. <br>
        <code><b>from tensorflow.keras.losses import ...</b></code>
        <br>Вот некоторые из них:
        <li><b>Mean Squared Error (MSE)</b></li>
        <li><b>Mean Absolute Error (MAE)</b></li>
        <li><b>Binary Cross-Entropy</b></li>
        <li><b>Categorical Cross-Entropy</b></li>
        <li>
          <b>Sparse Categorical Cross-Entropy</b> - Используется для многоклассовой классификации, когда метки классов представлены целыми числами, а не в виде one-hot кодирования.
        </li>
        <li><b>Hinge</b></li>
      </ol><br>
      <ul><b>Пользовательские функции потерь</b>
        <li>
          В Keras также можно определять собственные функции потерь. Например: <br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;import tensorflow as tf <br>
            <br>
            &nbsp;&nbsp;&nbsp;&nbsp;def custom_loss(y_true, y_pred): <br>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return tf.reduce_mean(tf.square(y_true - y_pred)) <br>
            <br>
            &nbsp;&nbsp;&nbsp;&nbsp;model.compile(optimizer='adam', loss=custom_loss)
          </code>
        </li>
      </ul><br>
      <p>Функции потерь играют критически важную роль в обучении моделей машинного обучения и нейронных сетей. Выбор правильной функции потерь зависит от задачи, которую необходимо решить (регрессия, классификация и т.д.), и структуры данных. Keras предоставляет удобные и легко настраиваемые инструменты для работы с различными функциями потерь, а также позволяет создавать собственные функции для специфических требований.</p>
    </div>
  </details>

  <!-- 4 -->
  <details class="details">
    <summary class="details__title">Оптимизаторы. Стандартные оптимизаторы keras.</summary>
    <div class="details__content">
      <p>
        Оптимизаторы играют ключевую роль в процессе обучения нейронных сетей, регулируя обновление весов на основе градиента функции потерь. Они определяют, как модель будет корректировать свои параметры для минимизации ошибки и улучшения предсказательной способности
      </p><br>
      <code><b>from tensorflow.keras.optimizers import ...</b></code><br><br>
      <ol><b>Основные оптимизаторы</b>
        <li>
          <b>Градиентный спуск (Gradient Descent)</b><br>Градиентный спуск обновляет параметры модели по направлению противоположному градиенту функции потерь:<b> θ=θ−η∇J(θ) </b><br>
          где:
          <ul>
            <li>θ — параметры модели,</li>
            <li>η — скорость обучения (learning rate),</li>
            <li>∇J(θ) — градиент функции потерь.</li>
          </ul>
          <br>
          <ul><b>Вариации градиентного спуска:</b>
            <li><b>Градиентный спуск с нулевой мини-партией (Batch Gradient Descent):</b> Использует весь обучающий набор данных для каждого шага обновления.</li>
            <li><b>Стохастический градиентный спуск (SGD):</b> Использует один случайный пример из обучающего набора данных для каждого шага обновления.</li>
            <li><b>Мини-пакетный градиентный спуск (Mini-Batch Gradient Descent):</b> Использует небольшие случайные подмножества данных для каждого шага обновления.</li>
          </ul>
        </li>
      </ol>
      <br><br>
      <ol><b>Стандартные оптимизаторы в Kera</b><br>Keras предоставляет несколько популярных оптимизаторов, которые можно использовать для обучения моделей.
        <li>
          <b>SGD (Stochastic Gradient Descent)</b> - Стохастический градиентный спуск с возможностью настройки момента (momentum) и затухания (decay).
          <ul><b><b>Аргументы:</b></b>
            <li><b>learning_rate:</b> Скорость обучения.</li>
            <li><b>momentum:</b> Параметр, который помогает ускорить SGD в правильном направлении и сгладить осцилляции.</li>
            <li><b>nesterov:</b> Логическое значение для использования Нестерова ускоренного градиента.</li>
          </ul>
        </li>
        <li>
          <b>Adam (Adaptive Moment Estimation)</b> - Adam — это популярный оптимизатор, который объединяет преимущества Adagrad и RMSProp. Он поддерживает индивидуальные скорости обучения для каждого параметра.
          <ul><b><b>Аргументы:</b></b>
            <li><b>learning_rate:</b> Скорость обучения.</li>
            <li><b>beta_1:</b> Параметр экспоненциального затухания для первого момента (по умолчанию 0.9).</li>
            <li><b>beta_2:</b> Параметр экспоненциального затухания для второго момента (по умолчанию 0.999).</li>
            <li><b>epsilon:</b> Маленькая константа для численной стабильности.</li>
          </ul>
        </li>
        <li>
          <b>RMSprop</b> - RMSprop оптимизирует градиентный спуск, поддерживая переменную скорость обучения для каждого параметра.
          <ul><b><b>Аргументы:</b></b>
            <li><b>learning_rate:</b> Скорость обучения.</li>
            <li><b>rho:</b> Параметр затухания для вычисления движущегося среднего квадратов градиентов.</li>
            <li><b>epsilon:</b> Маленькая константа для численной стабильности.</li>
          </ul>
        </li>
        <li>
          <b>Adagrad</b> - Adagrad адаптирует скорости обучения для каждого параметра, уменьшая скорость обучения по мере увеличения количества обновлений параметра.
          <ul><b><b>Аргументы:</b></b>
            <li><b>learning_rate:</b> Скорость обучения.</li>
            <li><b>epsilon:</b> Маленькая константа для численной стабильности.</li>
          </ul>
        </li>
        <li>
          <b>Adadelta</b> - Adadelta — расширение Adagrad, которое стремится уменьшить его агрессивное уменьшение скорости обучения.
          <ul><b><b>Аргументы:</b></b>
            <li><b>learning_rate:</b> Начальная скорость обучения.</li>
            <li><b>rho:</b> Параметр затухания для вычисления движущегося среднего квадратов градиентов.</li>
            <li><b>epsilon:</b> Маленькая константа для численной стабильности.</li>
          </ul>
        </li>
        <li>
          <b>Adamax</b> - Adamax — это вариант оптимизатора Adam на основе нормы 𝐿∞
          <ul><b><b>Аргументы:</b></b>
            <li><b>learning_rate:</b> Скорость обучения.</li>
            <li><b>beta_1:</b> Параметр экспоненциального затухания для первого момента.</li>
            <li><b>beta_2:</b> Параметр экспоненциального затухания для второго момента.</li>
            <li><b>epsilon:</b> Маленькая константа для численной стабильности.</li>
          </ul>
        </li>
        <li>
          <b>Nadam</b> - Nadam — это комбинация Adam и Nesterov ускоренного градиента.
          <ul><b><b>Аргументы:</b></b>
            <li><b>learning_rate:</b> Скорость обучения.</li>
            <li><b>beta_1:</b> Параметр экспоненциального затухания для первого момента.</li>
            <li><b>beta_2:</b> Параметр экспоненциального затухания для второго момента.</li>
            <li><b>epsilon:</b> Маленькая константа для численной стабильности.</li>
          </ul>
        </li>
      </ol><br>
      <p>Оптимизаторы играют важную роль в процессе обучения нейронных сетей, регулируя обновление параметров модели на основе градиента функции потерь. Выбор правильного оптимизатора и его гиперпараметров может существенно повлиять на производительность и скорость обучения модели. Keras предоставляет широкий спектр стандартных оптимизаторов, а также позволяет настраивать их параметры для различных задач и архитектур нейронных сетей.</p>
    </div>
  </details>

  <!-- 5 -->
  <details class="details">
    <summary class="details__title">Обучение нейронной сети. Выборки. Валидация данных.</summary>
    <div class="details__content">
      <p>Обучение нейронной сети — это процесс, в ходе которого модель настраивает свои параметры для минимизации функции ошибки и максимизации точности предсказаний. Этот процесс включает в себя несколько ключевых этапов, таких как разделение данных на выборки, обучение модели, валидация и тестирование.</p>
      <br>
      <ol><b>Выборки данных</b>
        <li>
          <b>Обучающая выборка (Training Set)</b><br>
          Обучающая выборка используется для непосредственного обучения модели. В этот этап модель настраивает свои параметры (веса и смещения) на основе данных и соответствующих им меток (labels).
          <ul>
            <li><b>Размер обучающей выборки:</b> Обычно составляет 70-80% от всех доступных данных</li>
            <li><b>Задача:</b> Минимизация функции потерь на обучающих данных.</li>
          </ul>
        </li>
        <li>
          <b>Валидационная выборка (Validation Set)</b><br>
          Валидационная выборка используется для оценки модели во время процесса обучения. Эти данные не используются для обновления параметров модели, а служат для мониторинга производительности модели и настройки гиперпараметров (например, скорости обучения, структуры сети).
          <ul>
            <li><b>Размер валидационной выборки:</b> Обычно составляет 10-15% от всех доступных данных.</li>
            <li><b>Задача:</b> Предотвращение переобучения и оптимизация гиперпараметров</li>
          </ul>
        </li>
        <li>
          <b>Тестовая выборка (Test Set)</b><br>
          Тестовая выборка используется для окончательной оценки модели после завершения обучения. Эти данные полностью отделены от процесса обучения и валидации.
          <ul>
            <li><b>Размер тестовой выборки:</b> Обычно составляет 10-15% от всех доступных данных.</li>
            <li><b>Задача:</b> Оценка обобщающей способности модели на новых, невиданных данных.</li>
          </ul>
        </li>
      </ol>
      <br>
      <ol><b>Валидация данных</b>
        <li>
          <b>Кросс-валидация (Cross-Validation)</b><br>
          Кросс-валидация — это метод оценки модели, при котором данные делятся на несколько частей (folds). Модель обучается на нескольких частях и проверяется на оставшихся, этот процесс повторяется несколько раз с различными частями данных.
          <ul>
            <li><b>K-fold кросс-валидация:</b> Данные делятся на K частей. Модель обучается на K-1 частях и проверяется на оставшейся части. Процесс повторяется K раз, и результаты усредняются.</li>
            <li><b>Преимущества:</b> Обеспечивает более надежную оценку модели, снижает влияние случайности в разделении данных.</li>
            <li><b>Недостатки:</b> Требует больше вычислительных ресурсов и времени.</li>
          </ul>
        </li>
        <li>
          <b>Рандомизированное разделение (Randomized Split)</b><br>
          Данные случайным образом разделяются на обучающую и валидационную выборки. Этот метод прост и эффективен, но может быть подвержен случайным отклонениям.
          <ul>
            <li><b>Преимущества:</b> Легкость реализации.</li>
            <li><b>Недостатки:</b> Может привести к неравномерному распределению данных, особенно при небольших выборках.</li>
          </ul>
        </li>
      </ol>
      <br>
      <ul><b>Обучение модели</b>
        <li>
          <b>Этапы обучения модели</b>
          <ol>
            <li><b>Инициализация:</b> Задание начальных значений параметров модели.</li>
            <li><b>Прямое распространение (Forward Propagation):</b> Вычисление предсказаний модели для данных.</li>
            <li><b>Вычесление ошибки (Loss Calculation):</b> Оценка разницы между предсказаниями модели и истинными значениями.</li>
            <li><b>Обратное распространение (Backpropagation):</b> Вычисление градиентов функции потерь по параметрам модели.</li>
            <li><b>Обновление параметров (Parameter Update):</b> Регулировка параметров модели с использованием оптимизатора.</li>
            <li><b>Повторение:</b> Процесс повторяется для каждой итерации (эпохи) обучения до достижения заданного числа эпох или остановки по другим критериям.</li>
          </ol>
        </li>
        <li>
          <b>Мониторинг процесса обучения</b>
          <ol>
            <li><b>Функция потерь (Loss Function):</b> Оценка ошибки модели на каждой эпохе обучения</li>
            <li><b>Метрики (Metrics):</b> Дополнительные метрики, такие как точность (accuracy), F1-score, ROC-AUC и другие, для оценки качества модели.</li>
          </ol>
        </li>
      </ul>
      <br><br>
      <p>Обучение нейронной сети включает в себя правильное разделение данных на выборки, оптимизацию модели с использованием функции потерь и оптимизаторов, а также мониторинг процесса обучения с помощью метрик и валидации. Эти этапы позволяют создать модель, которая хорошо обобщает на новых данных и минимизирует ошибки на обучающих данных.</p>
    </div>
  </details>

  <!-- 6 -->
  <details class="details">
    <summary class="details__title">Задача классификации. Формирование выборки, особенности построения архитектур НС.
    </summary>
    <div class="details__content">
      <p>Задача классификации — это один из основных типов задач в машинном обучении, где цель состоит в том, чтобы определить метку класса для входных данных. Классификация находит применение в таких областях, как распознавание образов, медицинская диагностика, фильтрация спама, анализ текста и многие другие.</p>
      <br>
      <ol><b>Формирование выборки</b><br>Для успешного решения задачи классификации необходимо правильно сформировать выборку данных. Процесс включает несколько этапов:
        <li>
          <b>Сбор данных</b><br>Данные могут быть получены из различных источников, таких как базы данных, веб-скрейпинг, сенсоры и т.д. Важно, чтобы данные были репрезентативными и содержали достаточное количество примеров для каждого класса.
        </li>
        <li>
          <b>Подготовка данных</b><br>На этом этапе данные обрабатываются для приведения их к виду, пригодному для обучения модели:
          <ul>
            <li><b>Очистка данных:</b> Удаление или коррекция пропущенных, аномальных и дублирующихся значений.</li>
            <li><b>Нормализация и стандартизация:</b> Приведение значений признаков к одному масштабу для улучшения сходимости алгоритма.</li>
            <li><b>Кодирование категориальных признаков:</b> Преобразование категориальных данных в числовые (например, с помощью one-hot encoding).</li>
          </ul>
        </li>
        <li>
          <b>Разделение данных</b><br>Для оценки производительности модели данные делятся на обучающую, валидационную и тестовую выборки:
          <ul>
            <li><b>Обучающая выборка:</b> Используется для обучения модели (обычно 70-80% данных).</li>
            <li><b>Валидационная выборка:</b> Используется для настройки гиперпараметров и предотвращения переобучения (10-15% данных).</li>
            <li><b>Тестовая выборка:</b> Используется для окончательной оценки модели (10-15% данных).</li>
          </ul>
        </li>
        <li>
          <b>Балансировка данных</b><br>В случае несбалансированных классов необходимо принять меры для улучшения производительности модели:
          <ul>
            <li><b>Увеличение выборки (Oversampling):</b> Искусственное увеличение количества примеров меньшего класса (например, с помощью SMOTE).</li>
            <li><b>Уменьшение выборки (Undersampling):</b> Уменьшение количества примеров большего класса.</li>
            <li><b>Создание синтетических данных:</b> Генерация новых примеров данных.</li>
          </ul>
        </li>
      </ol>
      <br><br>
      <ol><b>Особенности построения архитектур нейронных сетей для классификации</b><br>При построении архитектуры нейронной сети для задачи классификации необходимо учитывать несколько ключевых аспектов.
        <li>
          <b>Выбор типа нейронной сети</b>
          <ul>
            <li><b>Полносвязные сети (Dense или Fully Connected Layers):</b> Подходят для работы с табличными данными.</li>
            <li><b>Сверточные нейронные сети (CNN):</b> Эффективны для задач, связанных с изображениями.</li>
            <li><b>Рекуррентные нейронные сети (RNN) и их варианты (LSTM, GRU):</b> Используются для последовательных данных, таких как текст или временные ряды.</li>
          </ul>
        </li>
        <li>
          <b>Структура сети</b>
          <ul>
            <li><b>Количество слоев:</b> Глубина сети определяется сложностью задачи. Для простых задач может быть достаточно нескольких слоев, в то время как для более сложных задач требуется более глубокая сеть.</li>
            <li><b>Количество нейронов:</b> Количество нейронов в каждом слое также влияет на способность модели к обучению. Оно должно быть достаточно большим для захвата важной информации, но не слишком большим, чтобы избежать переобучения.</li>
          </ul>
        </li>
        <li>
          <b>Активационные функции</b>
          <ul>
            <li><b>ReLU (Rectified Linear Unit):</b> Часто используется в скрытых слоях, поскольку помогает справляться с проблемой исчезающего градиента.</li>
            <li><b>Sigmoid и Softmax:</b> Используются в выходном слое для бинарной и многоклассовой классификации соответственно.</li>
          </ul>
        </li>
        <li>
          <b>Регуляризация</b><br>Регуляризация помогает предотвратить переобучение и улучшает обобщающую способность модели:
          <ul>
            <li><b>Dropout:</b> Случайное выключение нейронов во время обучения.</li>
            <li><b>L1 и L2 регуляризация:</b> Добавление штрафов к функции потерь за большие веса.</li>
          </ul>
        </li>
        <li>
          <b>Оптимизаторы</b>
          <ul>
            <li><b>Adam:</b> Популярный оптимизатор, который адаптирует скорость обучения для каждого параметра.</li>
            <li><b>SGD (Stochastic Gradient Descent):</b> Классический метод, который может быть улучшен с помощью момента или адаптивных методов.</li>
          </ul>
        </li>
        <li>
          <b>Гиперпараметры</b>
          <ul>
            <li><b>Скорость обучения (Learning Rate):</b> Определяет размер шага при обновлении параметров модели.</li>
            <li><b>Размер пакета (Batch Size):</b> Количество примеров, используемых для одного шага обновления параметров.</li>
          </ul>
        </li>
      </ol>
      <br><br><p>Решение задачи классификации включает в себя правильное формирование выборки данных и построение соответствующей архитектуры нейронной сети. Важными аспектами являются балансировка данных, выбор типа нейронной сети, структура сети, активационные функции, регуляризация, оптимизаторы и настройка гиперпараметров. Правильное выполнение всех этих шагов позволяет создать эффективную модель, способную точно классифицировать новые данные.</p>
    </div>
  </details>

  <!-- 7 -->
  <details class="details">
    <summary class="details__title">Переобучение нейронной сети. Причины. Способы борьбы.</summary>
    <div class="details__content">
      <p>Переобучение (overfitting) — это ситуация, когда нейронная сеть слишком хорошо подстраивается под обучающие данные, включая шум и случайные колебания, и демонстрирует плохую обобщающую способность на новых, невиданных данных. Это приводит к высокой точности на обучающих данных, но низкой на валидационных и тестовых.</p>
      <br>
      <ol><b>Причины переобучения</b>
        <li><b>Сложность модели:</b> Слишком сложная модель с большим числом параметров может запомнить обучающие данные, включая шум.</li>
        <li><b>Недостаток данных:</b> Малое количество обучающих данных увеличивает риск запоминания вместо обобщения.</li>
        <li><b>Шум в данных:</b> Наличие шумовых или нерепрезентативных данных в обучающей выборке.</li>
        <li><b>Неправильная регуляризация:</b> Отсутствие или недостаточная регуляризация может позволить модели слишком точно подстраиваться под обучающие данные</li>
      </ol>
      <br><br>
      <ol><b>Способы борьбы с переобучением</b>
        <li>
          <b>Увеличение объема данных</b>
          <ul><b>Сбор дополнительных данных:</b> Больше данных позволяет модели лучше обобщать.<br>Методы:
            <li><b>Сбор новых данных:</b> Добавление новых примеров из различных источников.</li>
            <li><b>Аугментация данных (Data Augmentation):</b> Создание новых примеров из существующих данных (особенно в задачах компьютерного зрения).</li>
          </ul>
        </li>
        <li>
          <b>Регуляризация</b>
          <ul><b>L1 и L2 регуляризация:</b> Добавление штрафов за большие значения весов к функции потерь.
            <li>L2 регуляризация (Ridge): Loss = Loss + 𝜆∑𝑤^2</li>
            <li>L1 регуляризация (Lasso): Loss = Loss + λ∑|w|</li>
          </ul>
          <ul><b>Dropout:</b> Случайное отключение нейронов в слое во время обучения.
            <li>Пример: В каждом обновлении случайно выключается определенный процент нейронов, предотвращая их совместное использование.</li>
          </ul>
        </li>
        <li>
          <b>Уменьшение сложности модели</b>
          <ul><b>Сокращение числа параметров:</b> Уменьшение числа слоев или нейронов в сети.
            <li><b>Меньше слоев:</b> Уменьшение глубины сети.</li>
            <li><b>Меньше нейронов:</b> Уменьшение числа нейронов в каждом слое.</li>
          </ul>
        </li>
        <li>
          <b>Ранняя остановка (Early Stopping)</b>
          <ul><b>Остановка обучения при ухудшении валидационной ошибки:</b> Мониторинг валидационной ошибки и остановка, если она начинает увеличиваться.
            <li>Использование колбэка EarlyStopping в Keras: <code>early_stopping = EarlyStopping(monitor='val_loss', patience=5)</code></li>
          </ul>
        </li>
        <li>
          <b>Кросс-валидация (Cross-Validation)</b>
          <ul><b>Разделение данных на несколько частей:</b> Использование разных частей данных для обучения и валидации на каждом этапе.
            <li><b>K-fold кросс-валидация:</b> Данные делятся на K частей, и модель обучается K раз, каждый раз используя разные части для обучения и валидации.</li>
            <li>
              <code>
                &nbsp;&nbsp;&nbsp;&nbsp;from sklearn.model_selection import KFold <br>
                <br>
                &nbsp;&nbsp;&nbsp;&nbsp;kf = KFold(n_splits=5) <br>
                &nbsp;&nbsp;&nbsp;&nbsp;for train_index, val_index in kf.split(X): <br>
                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;X_train, X_val = X[train_index], X[val_index] <br>
                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;y_train, y_val = y[train_index], y[val_index] <br>
                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;model.fit(X_train, y_train, validation_data=(X_val, y_val))
              </code>
            </li>
          </ul>
        </li>
        <li>
          <b>Добавление шума к данным</b>
          <ul><b>Шум в обучающих данных:</b> Добавление шума к входным данным для увеличения их вариативности.
            <li><b>Гауссов шум (Gaussian Noise):</b> Добавление случайного шума к входным данным.</li>
            <li>
              <code>
                &nbsp;&nbsp;&nbsp;&nbsp;from tensorflow.keras.layers import GaussianNoise <br>
                <br>
                &nbsp;&nbsp;&nbsp;&nbsp;model.add(GaussianNoise(0.1))  # Добавление шума с стандартным отклонением 0.1
              </code>
            </li>
          </ul>
        </li>
      </ol>
      <br><br>
      <p>Переобучение является одной из главных проблем в обучении нейронных сетей, однако существует множество методов для его предотвращения. Ключевыми методами являются увеличение объема данных, регуляризация, уменьшение сложности модели, ранняя остановка и кросс-валидация. Применение этих методов помогает улучшить обобщающую способность модели и добиться лучшего качества предсказаний на новых данных.</p>
    </div>
  </details>

  <!-- 8 -->
  <details class="details">
    <summary class="details__title">Особенности построения моделей с помощью Sequential и FunctionalAPI.</summary>
    <div class="details__content">
      <p><b>Sequential API</b></p>
      <p>Sequential API в Keras предоставляет простой и интуитивно понятный способ создания моделей, где слои следуют друг за другом. Этот метод удобен для построения простых моделей, таких как многослойные перцептроны или базовые сверточные сети. Sequential API идеально подходит для тех случаев, когда структура модели является линейной, то есть данные проходят через слои последовательно без разветвлений и объединений. Этот подход прост в использовании и хорошо подходит для начинающих, так как требует минимальных усилий для понимания и реализации.</p>
      <br>
      <p><b>Functional API</b></p>
      <p>Functional API предлагает большую гибкость и позволяет создавать сложные модели с нелинейными структурами, включая модели с несколькими входами и выходами, а также с ветвлениями и объединениями. В отличие от Sequential API, Functional API позволяет точно контролировать потоки данных и связи между слоями, что делает его идеальным для сложных архитектур. С Functional API вы можете свободно комбинировать слои и определять, как данные будут проходить через модель. Этот подход особенно полезен для реализации таких сложных архитектур, как остаточные сети (ResNet), сетевые сети (Inception) и других сложных структур.</p>
      <br>
      <p><b>Применение и гибкость</b></p>
      <p>Functional API позволяет реализовывать сложные архитектуры, что делает его более гибким инструментом по сравнению с Sequential API. Например, вы можете легко создать модель с несколькими входами и выходами, объединить или разветвить потоки данных, а также повторно использовать один и тот же слой в нескольких местах модели. Однако, если ваша задача требует построения простой линейной модели, такой как многослойный перцептрон или простая сверточная нейронная сеть, Sequential API будет более подходящим выбором из-за его простоты и удобства.</p>
      <br>
      <p><b>Заключение</b></p>
      <p>Sequential API и Functional API в Keras предоставляют различные уровни гибкости для построения нейронных сетей. Sequential API является отличным выбором для простых, линейных моделей благодаря своей простоте и интуитивно понятному интерфейсу. В то время как Functional API предоставляет мощные инструменты для создания сложных, нелинейных архитектур и позволяет реализовывать более гибкие и продвинутые модели. Понимание этих двух подходов поможет вам выбрать наиболее подходящий инструмент для решения конкретной задачи машинного обучения.</p>
      <br><br>
      <ol><b>Практические примеры использования</b>
        <li>
          <b>Sequential API:</b>
          <ul>
            <li>Простые модели классификации изображений с несколькими сверточными и плотными слоями.</li>
            <li>Многослойные перцептроны для задач регрессии и классификации.</li>
          </ul>
        </li>
        <li>
          <b>Functional API:</b>
          <ul>
            <li>Сложные архитектуры, такие как ResNet, где необходимы остаточные соединения.</li>
            <li>Модели внимания, где требуется динамическое взвешивание частей входных данных.</li>
            <li>Автоэнкодеры для задач сжатия данных и аномалий.</li>
          </ul>
        </li>
      </ol>
      <br><br>
      <p><b>Совместное использование Sequential и Functional API</b></p><p>Иногда может быть полезно комбинировать Sequential и Functional API. Например, можно создать части модели с помощью Sequential API и затем интегрировать их в более сложную архитектуру с Functional API. Это позволяет достичь баланса между простотой и гибкостью.</p>
      <br>
      <ol><b>Примеры из реальной жизни</b>
        <li><b>Sequential API</b> часто используется для обучения студентов и начинающих исследователей, предоставляя им простой способ изучения основных концепций нейронных сетей.</li>
        <li><b>Functional API</b> используется в промышленных приложениях и исследовательских проектах, где требуется высокая гибкость и способность адаптироваться к сложным и нестандартным задачам.</li>
      </ol>
    </div>
  </details>

  <!-- 9 -->
  <details class="details">
    <summary class="details__title">Линейный слой Dense. Устройство слоя.</summary>
    <div class="details__content">
      <p><b>Основы линейного слоя Dense</b></p>
      <p>Линейный слой, также известный как плотный слой (Dense), является одним из основных строительных блоков нейронных сетей. В Keras и других библиотеке машинного обучения слой Dense выполняет линейное преобразование входных данных с добавлением смещения (bias) и применением функции активации.</p>
      <br>
      <p>Основное уравнение, описывающее операцию слоя Dense, можно представить следующим образом: <br><code>y = f(W*x + b)</code></p>
      <p>где:</p>
      <ul>
        <li>x — входной вектор,</li>
        <li>W — матрица весов,</li>
        <li>b — вектор смещений,</li>
        <li>f — функция активации,</li>
        <li>y — выходной вектор.</li>
      </ul>
      <br><br>
      <ol><b>Устройство слоя Dense</b>
        <li><b>Входные данные:</b> <br>Входные данные слоя Dense могут быть вектором или матрицей. Вектор используется для работы с одномерными данными, такими как числовые признаки, тогда как матрица применяется для двумерных данных, таких как изображения (после предварительной обработки).</li>
        <li><b>Матрица весов:</b> <br>Матрица весов W представляет собой набор параметров, которые обучаются в процессе тренировки модели. Размерность матрицы зависит от числа входных и выходных нейронов. Для слоя Dense с n входами и m выходами матрица весов имеет размерность n*m.</li>
        <li><b>Вектор смещений:</b> <br>Вектор смещений b добавляется к результату умножения входных данных на матрицу весов. Этот вектор также является параметром, который обучается. Размерность вектора смещений соответствует числу выходных нейронов.</li>
        <li><b>Функция активации:</b> <br>Функция активации f применяется к линейному преобразованию входных данных. Она добавляет нелинейность в модель, что позволяет решать более сложные задачи. Наиболее часто используемые функции активации включают ReLU (Rectified Linear Unit), сигмоидальную функцию и гиперболический тангенс (tanh).</li>
      </ol>
      <br><br>
      <p><b>Работа слоя Dense в нейронной сети</b></p>
      <p>Когда входной вектор поступает на слой Dense, он умножается на матрицу весов W, затем к результату добавляется вектор смещений b. Полученное значение передается через функцию активации f, которая вводит нелинейность. Выходные значения этого процесса передаются на следующий слой или являются окончательным результатом сети.</p>
      <br>
      <p><b>Обучение слоя Dense</b></p>
      <p>В процессе обучения нейронной сети значения матрицы весов W и вектора смещений b корректируются таким образом, чтобы минимизировать функцию потерь, которая измеряет расхождение между предсказанными и истинными значениями. Для этого используются различные оптимизационные алгоритмы, такие как градиентный спуск.</p>
      <br><p><b>Роль слоя Dense в нейронной сети</b></p>
      <p>Слой Dense играет ключевую роль в нейронных сетях, особенно в многослойных перцептронах и глубоких нейронных сетях. Он обеспечивает связь между нейронами и позволяет модели захватывать сложные зависимости в данных. В сочетании с различными функциями активации и другими слоями, такими как сверточные или рекуррентные, слой Dense помогает строить мощные модели для решения широкого спектра задач, включая классификацию, регрессию и кластеризацию.</p>
      <br>
      <p>Линейный слой Dense является фундаментальным компонентом нейронных сетей. Он выполняет линейное преобразование входных данных, добавляет смещение и применяет функцию активации, создавая сложные нелинейные модели. Понимание устройства и работы слоя Dense является важным шагом в изучении и разработке нейронных сетей.</p>
    </div>
  </details>

  <!-- 10 -->
  <details class="details">
    <summary class="details__title">Сверточный слой Conv2D. Основные параметры слоя.</summary>
    <div class="details__content">
      <p>Сверточный слой (Conv2D) является основным компонентом сверточных нейронных сетей (CNN), которые широко используются для обработки изображений и других двумерных данных. Слой Conv2D выполняет свертку входных данных с набором фильтров (ядра), что позволяет извлекать локальные особенности из данных, такие как края, текстуры и паттерны.</p>
      <br>
      <ol><b>Основные параметры слоя Conv2D</b>
        <li>
          <b>filters (фильтры):</b>
          <ul>
            <li><b>Описание:</b> Количество фильтров (ядер свертки) в слое</li>
            <li><b>Значение:</b> Положительное целое число.</li>
            <li><b>Роль:</b> Каждый фильтр извлекает различные особенности из входных данных. Большее количество фильтров позволяет извлекать большее количество разнообразных признаков, но также увеличивает вычислительную сложность.</li>
          </ul>
        </li>
        <li>
          <b>kernel_size (размер ядра):</b>
          <ul>
            <li><b>Описание:</b> Размер каждого фильтра (ядра свертки).</li>
            <li><b>Значение:</b> Кортеж из двух целых чисел (высота, ширина) или одно целое число (если высота и ширина равны).</li>
            <li><b>Роль:</b> Размер ядра определяет область восприятия фильтра. Меньшие ядра лучше подходят для извлечения мелких особенностей, тогда как большие ядра могут захватывать более глобальные паттерны.</li>
          </ul>
        </li>
        <li>
          <b>strides (шаги):</b>
          <ul>
            <li><b>Описание:</b> Шаги свертки по высоте и ширине.</li>
            <li><b>Значение:</b> Кортеж из двух целых чисел (вертикальный шаг, горизонтальный шаг) или одно целое число (если шаги одинаковы).</li>
            <li><b>Роль:</b> Шаг определяет, насколько далеко перемещается ядро свертки по входным данным. Большие шаги уменьшают размер выходного тензора, но могут пропускать некоторые особенности.</li>
          </ul>
        </li>
        <li>
          <b>padding (отступы):</b>
          <ul>
            <li><b>Описание:</b> Способ обработки краев входных данных.</li>
            <li><b>Значение:</b> Строка 'valid' (без отступов) или 'same' (с отступами, чтобы сохранить размер входа).</li>
            <li><b>Роль:</b> 'valid' приводит к уменьшению размера выходного тензора, тогда как 'same' сохраняет размер, добавляя нулевые отступы по краям.</li>
          </ul>
        </li>
        <li>
          <b>activation (функция активации):</b>
          <ul>
            <li><b>Описание:</b> Функция активации, применяемая к выходу свертки.</li>
            <li><b>Значение:</b> Строка, определяющая тип активации (например, 'relu', 'sigmoid', 'tanh').</li>
            <li><b>Роль:</b> Добавление нелинейности в модель, что позволяет извлекать более сложные особенности.</li>
          </ul>
        </li>
        <li>
          <b>input_shape (форма входных данных):</b>
          <ul>
            <li><b>Описание:</b> Форма входных данных.</li>
            <li><b>Значение:</b> Кортеж, определяющий размерность входных данных (высота, ширина, количество каналов).</li>
            <li><b>Роль:</b> Указывается только для первого слоя в модели, чтобы определить размерность входного тензора.</li>
          </ul>
        </li>
        <li>
          <b>kernel_initializer (инициализация весов):</b>
          <ul>
            <li><b>Описание:</b> Метод инициализации весов ядра свертки.</li>
            <li><b>Значение:</b> Строка, определяющая метод инициализации (например, 'glorot_uniform', 'he_normal').</li>
            <li><b>Роль:</b> Выбор подходящего метода инициализации помогает улучшить сходимость и качество обучения модели.</li>
          </ul>
        </li>
        <li>
          <b>bias_initializer (инициализация смещений):</b>
          <ul>
            <li><b>Описание:</b> Метод инициализации смещений.</li>
            <li><b>Значение:</b> Строка, определяющая метод инициализации (например, 'zeros', 'ones').</li>
            <li><b>Роль:</b> Инициализация смещений влияет на начальные значения смещений, которые затем корректируются в процессе обучения.</li>
          </ul>
        </li>
        <li>
          <b>kernel_regularizer (регуляризация весов):</b>
          <ul>
            <li><b>Описание:</b> Регуляризатор, применяемый к весам ядра свертки.</li>
            <li><b>Значение:</b> Объект регуляризации (например, tf.keras.regularizers.l2(0.01)).</li>
            <li><b>Роль:</b> Регуляризация помогает предотвратить переобучение, добавляя штраф за сложность модели.</li>
          </ul>
        </li>
        <li>
          <b>bias_regularizer (регуляризация смещений):</b>
          <ul>
            <li><b>Описание:</b> Регуляризатор, применяемый к смещениям.</li>
            <li><b>Значение:</b> Объект регуляризации.</li>
            <li><b>Роль:</b> Аналогично регуляризации весов, помогает предотвратить переобучение.</li>
          </ul>
        </li>
      </ol><br><br>
      <p><b>Работа слоя Conv2D в нейронной сети</b></p>
      <p>Слой Conv2D обрабатывает входные данные, применяя свертку с заданными фильтрами. Для каждого фильтра ядро перемещается по входному тензору, вычисляя свертку (линейное преобразование с последующей нелинейностью) для каждой позиции. Результаты сверток для всех фильтров объединяются, образуя выходной тензор.</p>
      <br>
      <p><b>Применение сверточных слоев</b></p>
      <p>Сверточные слои широко используются в задачах компьютерного зрения, таких как распознавание образов, классификация изображений, сегментация, детекция объектов и многие другие. Они также находят применение в обработке сигналов, аудио и текстовых данных.</p>
      <br>
      <p>Сверточный слой Conv2D является мощным инструментом для извлечения особенностей из двумерных данных. Понимание основных параметров слоя Conv2D, таких как количество фильтров, размер ядра, шаги, отступы и функции активации, позволяет эффективно настраивать и использовать этот слой в нейронных сетях для решения различных задач.</p>
    </div>
  </details>

  <!-- 11 -->
  <details class="details">
    <summary class="details__title">Pooling-слои.(Определения, назначения, принцип работы, основные параметры, варианты и правила применения, основные параметры)</summary>
    <div class="details__content">
      <p><b>Определение и назначение</b></p>
      <p>Pooling-слои (слои подвыборки) используются в сверточных нейронных сетях (CNN) для уменьшения размерности входных данных, уменьшения вычислительной сложности и извлечения устойчивых признаков. Эти слои снижают пространственные размеры (высоту и ширину) входных данных, сохраняя наиболее важную информацию. Pooling помогает делать модель более инвариантной к небольшим сдвигам и искажениям.</p>
      <br>
      <p><b>Принцип работы</b></p>
      <p>Pooling-слои выполняют подвыборку на входных данных с использованием фиксированного окна, которое перемещается по входному тензору. В каждом положении окна вычисляется агрегатное значение, например, максимальное значение (max pooling) или среднее значение (average pooling), которое затем становится частью выходного тензора.</p>
      <br>
      <ol><b>Основные параметры</b>
        <li>
          <b>pool_size (размер окна подвыборки):</b>
          <ul>
            <li><b>Описание:</b> Размер окна подвыборки по высоте и ширине.</li>
            <li><b>Значение:</b> Кортеж из двух целых чисел (высота, ширина) или одно целое число (если высота и ширина равны).</li>
            <li><b>Роль:</b> Определяет область, в которой будет производиться подвыборка. Например, размер (2, 2) означает, что окно подвыборки охватывает 2x2 области входного тензора.</li>
          </ul>
        </li>
        <li>
          <b>strides (шаги):</b>
          <ul>
            <li><b>Описание:</b> Шаги перемещения окна подвыборки по высоте и ширине.</li>
            <li><b>Значение:</b> Кортеж из двух целых чисел (вертикальный шаг, горизонтальный шаг) или одно целое число (если шаги одинаковы).</li>
            <li><b>Роль:</b> Определяет, насколько далеко окно подвыборки перемещается по входным данным. Если шаги меньше размера окна, происходит перекрытие подвыборки.</li>
          </ul>
        </li>
        <li>
          <b>padding (отступы):</b>
          <ul>
            <li><b>Описание:</b> Способ обработки краев входных данных.</li>
            <li><b>Значение:</b> Строка 'valid' (без отступов) или 'same' (с отступами, чтобы сохранить размер входа).</li>
            <li><b>Роль:</b> 'valid' приводит к уменьшению размера выходного тензора, тогда как 'same' сохраняет размер, добавляя нулевые отступы по краям.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol><b>Варианты и правила применения</b>
        <li>
          <b>Max Pooling (максимальная подвыборка):</b>
          <ul>
            <li><b>Описание:</b> В каждой области окна подвыборки выбирается максимальное значение.</li>
            <li><b>Применение:</b> Часто используется для извлечения ярко выраженных признаков, таких как края и углы.</li>
            <li><b>Пример:</b> MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')</li>
          </ul>
        </li>
        <li>
          <b>Average Pooling (средняя подвыборка):</b>
          <ul>
            <li><b>Описание:</b> В каждой области окна подвыборки вычисляется среднее значение.</li>
            <li><b>Применение:</b> Используется для уменьшения шумов и более гладкой подвыборки признаков.</li>
            <li><b>Пример:</b> AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')</li>
          </ul>
        </li>
        <li>
          <b>Global Pooling (глобальная подвыборка):</b>
          <ul>
            <li><b>Описание:</b> Применяется ко всему тензору, вычисляя одно агрегатное значение для каждой карты признаков.</li>
            <li><b>Применение:</b> Часто используется перед полностью связанными (Dense) слоями для уменьшения размерности и подготовки признаков к классификации.</li>
            <li><b>Пример:</b> GlobalMaxPooling2D(), GlobalAveragePooling2D()</li>
          </ul>
        </li>
      </ol><br><br>
      <ol><b>Принципы применения</b>
        <li><b>Уменьшение размерности:</b> Pooling-слои помогают уменьшить пространственные размеры данных, снижая вычислительную сложность последующих слоев.</li>
        <li><b>Извлечение устойчивых признаков:</b> Pooling делает модель более инвариантной к небольшим сдвигам и искажениям, улучшая способность модели к обобщению.</li>
        <li><b>Комбинирование со сверточными слоями:</b> Pooling-слои часто чередуются со сверточными слоями, чтобы последовательно уменьшать размерность данных и извлекать признаки на различных уровнях абстракции.</li>
        <li><b>Регулирование размеров данных:</b> Правильный выбор размеров окна подвыборки и шагов помогает контролировать степень уменьшения размерности и избегать чрезмерного уменьшения.</li>
      </ol><br><br>
      <p>Pooling-слои являются важным компонентом сверточных нейронных сетей, обеспечивая уменьшение размерности и извлечение устойчивых признаков из входных данных. Понимание различных типов pooling-слоев, их параметров и принципов применения помогает эффективно использовать эти слои для построения мощных моделей для обработки изображений и других задач, связанных с анализом двумерных данных.</p>
    </div>
  </details>

  <!-- 12 -->
  <details class="details">
    <summary class="details__title">Tokenizer. Применение, основные параметры.</summary>
    <div class="details__content">
      <p>`Tokenizer` — это инструмент, предоставляемый библиотекой Keras для предварительной обработки текстовых данных перед подачей их в модели машинного обучения. Он решает задачу преобразования текста в числовые последовательности, которые могут быть использованы нейронными сетями. Токенизатор помогает подготовить текстовые данные для обучения, обработки и анализа в рамках задач обработки естественного языка (NLP).</p>
      <br>
      <ol><b>Основные этапы применения Tokenizer</b>
        <li>
          <b>Токенизация</b>
          <ul>
            <li>Разделение текста на отдельные слова или символы (токены).</li>
            <li>Преобразование этих токенов в числовые значения.</li>
          </ul>
        </li>
        <li>
          <b>Создание словаря</b>
          <ul>
            <li>Построение словаря, содержащего уникальные токены и их соответствующие числовые представления</li>
            <li>Словарь сопоставляет каждому слову (или символу) уникальный индекс</li>
          </ul>
        </li>
        <li>
          <b>Преобразование текста</b>
          <ul>
            <li>Преобразование текстовых данных в последовательности чисел на основе словаря</li>
            <li>Применение паддинга и усечения для приведения всех последовательностей к одной длине</li>
          </ul>
        </li>
      </ol><br><br>
      <ol><b>Основные параметры</b>
        <li>
          <b>num_words:</b>
          <ul>
            <li><b>Описание:</b> Максимальное количество слов, которые будут учитываться в словаре.</li>
            <li><b>Значение:</b> Положительное целое число.</li>
            <li><b>Роль:</b> Ограничивает размер словаря, сохраняя только наиболее часто встречающиеся слова. Это помогает избежать работы с редкими словами, которые могут увеличить вычислительную сложность и снизить качество модели.</li>
          </ul>
        </li>
        <li>
          <b>filters:</b>
          <ul>
            <li><b>Описание:</b> Строка, содержащая символы, которые будут удалены из текста.</li>
            <li><b>Значение:</b> По умолчанию !"#$%&()*+,-./:;<=>?@[\\]^_{|}~\t\n`.</li>
            <li><b>Роль:</b> Удаляет указанные символы из текста перед токенизацией, что помогает очистить данные от ненужных знаков препинания и специальных символов.</li>
          </ul>
        </li>
        <li>
          <b>lower:</b>
          <ul>
            <li><b>Описание:</b> Преобразовывать ли текст в нижний регистр.</li>
            <li><b>Значение:</b> Булево значение (True или False).</li>
            <li><b>Роль:</b> Приведение текста к нижнему регистру для обеспечения консистентности. Это полезно, чтобы слова, написанные в разном регистре (например, "Пример" и "пример"), не считались разными токенами.</li>
          </ul>
        </li>
        <li>
          <b>split:</b>
          <ul>
            <li><b>Описание:</b> Символ, используемый для разделения слов.</li>
            <li><b>Значение:</b> Строка (по умолчанию пробел ' ').</li>
            <li><b>Роль:</b> Определяет разделитель для токенизации текста. Можно использовать другой символ, например, запятую, если текст представляет собой список значений, разделенных запятыми.</li>
          </ul>
        </li>
        <li>
          <b>char_level:</b>
          <ul>
            <li><b>Описание:</b> Токенизировать ли на уровне символов.</li>
            <li><b>Значение:</b> Булево значение (True или False).</li>
            <li><b>Роль:</b> Определяет, будет ли токенизация проводиться на уровне символов вместо слов. Это полезно для задач, где необходимо анализировать структуру слов, такие как морфологический анализ или задачи распознавания именованных сущностей.</li>
          </ul>
        </li>
        <li>
          <b>oov_token:</b>
          <ul>
            <li><b>Описание:</b> Токен для слов, отсутствующих в словаре (out-of-vocabulary).</li>
            <li><b>Значение:</b> Строка или None.</li>
            <li><b>Роль:</b> Специальный токен для слов, которые не были встречены при обучении токенизатора. Это помогает модели справляться с новыми или редкими словами, которые не встречались в обучающем наборе данных.</li>
          </ul>
        </li>
      </ol><br>
      <p><b>Работа с Tokenizer</b></p>
      <br>
      <ol><b>Шаги использования Tokenizer</b>
        <li>
          <b>Создание объекта Tokenizer с заданными параметрами.</b><br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;from keras.preprocessing.text import Tokenizer <br>
            &nbsp;&nbsp;&nbsp;&nbsp;tokenizer = Tokenizer(num_words=10000)
          </code>
        </li>
        <li>
          <b>Обучение токенизатора на текстовых данных:</b> Токенизатор анализирует текст и строит словарь частотности слов. <br>
          <code>
            &nbsp;&nbsp;&nbsp;&nbsp;texts = ["Пример текста для токенизации", "Еще один пример текста"] <br>
            &nbsp;&nbsp;&nbsp;&nbsp;tokenizer.fit_on_texts(texts)
          </code>
        </li>
        <li>
          <b>Преобразование текстов в последовательности чисел: </b>Текстовые данные преобразуются в последовательности чисел на основе словаря. <br>
          <code>&nbsp;&nbsp;&nbsp;&nbsp;sequences = tokenizer.texts_to_sequences(texts)</code>
        </li>
        <li>
          <b>Преобразование последовательностей обратно в текст: </b>Восстановление текстов из числовых последовательностей (для отладки и анализа). <br>
          <code>&nbsp;&nbsp;&nbsp;&nbsp;texts_back = tokenizer.sequences_to_texts(sequences)</code>
        </li>
      </ol><br><br>
      <ol><b>Дополнительные возможности и детали Tokenizer</b>
        <li>
          <b>Методы Tokenizer:</b>
          <ul>
            <li><b>fit_on_texts(texts):</b> Анализирует список текстов и строит внутренний словарь токенов. Этот метод создает индексы для каждого слова, основываясь на их частоте в текстах.</li>
            <li><b>texts_to_sequences(texts):</b> Преобразует список текстов в список последовательностей чисел, где каждое число представляет индекс токена в словаре.</li>
            <li><b>texts_to_matrix(texts, mode='binary'):</b> Преобразует тексты в матрицу (например, частотную или бинарную), где строки представляют тексты, а столбцы — токены.</li>
            <li><b>sequences_to_texts(sequences):</b> Преобразует список последовательностей чисел обратно в список текстов.</li>
            <li><b>sequences_to_matrix(sequences, mode='binary'):</b> Преобразует последовательности в матрицу аналогично texts_to_matrix.</li>
          </ul>
        </li>
        <li>
          <b>Типы матриц в методе texts_to_matrix:</b>
          <ul>
            <li><b>binary:</b> Матрица, где присутствие слова обозначается 1, а его отсутствие — 0.</li>
            <li><b>count:</b> Матрица с подсчетом количества появлений каждого слова в тексте.</li>
            <li><b>tfidf:</b> Матрица с TF-IDF значениями, где учитывается частота появления слова и обратная частота документа.</li>
            <li><b>freq:</b> Матрица с частотой появления слов в тексте.</li>
          </ul>
        </li>
        <li>
          <b>Работа с различными языками и кодировками:</b>
          <ul>
            <li>Токенизатор может работать с текстами на разных языках и с различными кодировками. Это важно для многокультурных и многоязычных приложений.</li>
          </ul>
        </li>
        <li>
          <b>Учет последовательностей слов:</b>
          <ul>
            <li>Tokenizer может использоваться для обработки не только отдельных слов, но и фраз или последовательностей слов, что полезно в задачах анализа последовательностей и временных рядов.</li>
          </ul>
        </li>
        <li>
          <b>Совместимость с другими инструментами NLP:</b>
          <ul>
            <li>Tokenizer легко интегрируется с другими библиотеками и инструментами для обработки естественного языка, такими как NLTK и spaCy. Это позволяет комбинировать его возможности с более продвинутыми техниками NLP.</li>
          </ul>
        </li>
        <li>
          <b>Обработка больших данных:</b>
          <ul>
            <li>Tokenizer можно применять для обработки больших корпусов текстов. Важно оптимизировать процесс, используя параметры num_words и oov_token, чтобы уменьшить размер словаря и ускорить обработку.</li>
          </ul>
        </li>
        <li>
          <b>Обратная совместимость и обновления:</b>
          <ul>
            <li>Keras и TensorFlow регулярно обновляют свои библиотеки, добавляя новые возможности и улучшая производительность. Текущие и будущие версии могут включать дополнительные параметры и методы для токенизации.</li>
          </ul>
        </li>
        <li>
          <b>Примеры практического использования:</b>
          <ul>
            <li><b>Анализ настроений:</b> Преобразование текстов отзывов пользователей в числовые последовательности для дальнейшего анализа настроений с использованием нейронных сетей.</li>
            <li><b>Чат-боты:</b> Обработка пользовательских запросов и генерация ответов в текстовом формате.</li>
            <li><b>Классификация текстов:</b> Подготовка текстовых данных для задач классификации, таких как определение темы или категории текста.</li>
            <li><b>Машинный перевод:</b> Преобразование текстов на одном языке в последовательности для дальнейшего перевода на другой язык с использованием моделей Seq2Seq.</li>
          </ul>
        </li>
      </ol><br>
      <p>Tokenizer в Keras — это мощный инструмент для предварительной обработки текстовых данных. Он предоставляет множество возможностей для гибкой и эффективной работы с текстами, что делает его незаменимым в задачах обработки естественного языка и машинного обучения. Разнообразие параметров и методов позволяет адаптировать его под конкретные нужды и задачи, обеспечивая высокое качество подготовки данных для моделей.</p>
    </div>
  </details>

  <!-- 13 -->
  <details class="details">
    <summary class="details__title">Параметризация текста BagOfWords.</summary>
    <div class="details__content">
      <p>Bag of Words (BoW) — это один из самых простых и широко используемых методов представления текстов в числовой форме, применяемый в задачах обработки естественного языка (NLP) и машинного обучения. Основная идея BoW заключается в том, чтобы представить текст как "мешок" слов, игнорируя порядок слов, синтаксис и даже грамматику. BoW используется для преобразования текстов в векторы фиксированной длины, что позволяет использовать их в моделях машинного обучения.</p>
      <ol><b>Основные этапы метода BoW</b>
        <li>
          <b>Токенизация текста:</b>
          <ul>
            <li>Процесс разбиения текста на отдельные слова или токены.</li>
            <li>Токены могут быть словами, символами или фразами в зависимости от задачи.</li>
            <li>Пример: предложение "машинное обучение это круто" будет токенизировано в ["машинное", "обучение", "это", "круто"].</li>
          </ul>
        </li>
        <li>
          <b>Создание словаря:</b>
          <ul>
            <li>Словарь (или лексикон) содержит все уникальные слова, найденные в корпусе текстов.</li>
            <li>Каждому уникальному слову присваивается уникальный индекс.</li>
            <li>Словарь может включать или исключать слова на основе их частоты (например, исключение редких слов или слов, встречающихся слишком часто, как стоп-слова)</li>
          </ul>
        </li>
        <li>
          <b>Построение векторов признаков:</b>
          <ul>
            <li>Каждое предложение или документ преобразуется в вектор, длина которого равна размеру словаря.</li>
            <li>Значения в векторе обычно представляют собой частоты появления слов в тексте, хотя возможны и другие варианты, такие как бинарные значения (присутствие/отсутствие слова).</li>
          </ul>
        </li>
      </ol><br><br>
      <ol><b>Модификации и улучшения BoW</b>
        <li>
          <b>Бинарное представление:</b>
          <ul>
            <li>Вместо подсчета частот слов используется бинарное значение: 1, если слово присутствует в тексте, и 0, если отсутствует.</li>
            <li>Это может быть полезно, когда важен факт наличия слова, а не его частота.</li>
          </ul>
        </li>
        <li>
          <b>TF-IDF (Term Frequency-Inverse Document Frequency):</b>
          <ul>
            <li>Модификация BoW, которая учитывает не только частоту слова в тексте, но и его значимость в корпусе.</li>
            <li><b>TF (частота термина):</b> количество появлений слова в документе.</li>
            <li><b>IDF (обратная частота документа):</b> логарифм от общего числа документов в корпусе, деленный на количество документов, содержащих это слово.</li>
            <li>TF-IDF помогает уменьшить влияние часто встречающихся слов, таких как "и", "в", "на", которые могут быть менее информативными.</li>
          </ul>
        </li>
      </ol><br><br>
      <ul><b>Преимущества и недостатки метода BoW</b>
        <li>
          <ul><b>Преимущества:</b>
            <li><b>Простота реализации:</b> BoW легко понять и внедрить, не требует сложных вычислений.</li>
            <li><b>Прозрачность:</b> Результирующие векторы легко интерпретировать.</li>
            <li><b>Совместимость:</b> Подходит для множества алгоритмов машинного обучения, таких как логистическая регрессия, SVM, наивный Байес и т.д.</li>
          </ul>
        </li>
        <li>
          <ul><b>Недостатки:</b>
            <li><b>Игнорирование порядка слов:</b> BoW не учитывает порядок слов, что может быть критическим для понимания контекста.</li>
            <li><b>Высокая размерность:</b> Размер векторов равен размеру словаря, что может приводить к проблемам с памятью и вычислительными ресурсами при работе с большими корпусами.</li>
            <li><b>Проблема синонимов и полисемии:</b> BoW не учитывает синонимы (разные слова с одинаковым значением) и полисемию (одно слово с разными значениями).</li>
            <li><b>Разреженность данных:</b> Большинство векторов будут содержать много нулей, так как в каждом тексте используется лишь небольшая часть словаря</li>
          </ul>
        </li>
      </ul><br><br>
      <ol><b>Применение BoW в реальных задачах</b>
        <li>
          <b>Классификация текстов:</b>
          <ul>
            <li>BoW часто используется для классификации текстов, таких как определение тематики, спам-фильтры и анализ настроений.</li>
            <li><b>Пример:</b> использование BoW для классификации новостей по категориям (спорт, политика, экономика и т.д.).</li>
          </ul>
        </li>
        <li>
          <b>Анализ настроений:</b>
          <ul>
            <li>Преобразование отзывов пользователей в векторы признаков для анализа положительных или отрицательных эмоций.</li>
            <li><b>Пример:</b> классификация отзывов на продукты как положительные или отрицательные.</li>
          </ul>
        </li>
        <li>
          <b>Информационный поиск:</b>
          <ul>
            <li>Представление документов и запросов в виде векторов для вычисления сходства и ранжирования результатов поиска.</li>
            <li><b>Пример:</b> поисковые системы используют BoW для индексации и поиска релевантных документов.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol><b>Современные альтернативы BoW</b>
        <li>
          <b>Word Embeddings (встраивания слов):</b>
          <ul>
            <li>Методы, такие как Word2Vec, GloVe и FastText, создают плотные векторы для слов, которые учитывают семантические отношения между словами</li>
            <li>Встраивания слов представляют слова в многомерных пространствах, где семантически похожие слова имеют близкие вектора.</li>
          </ul>
        </li>
        <li>
          <b>Contextual Embeddings:</b>
          <ul>
            <li>Модели, такие как BERT и GPT, создают векторы для слов, учитывая их контекст в предложении.</li>
            <li>Эти методы позволяют моделям лучше понимать значения слов в зависимости от их окружения.</li>
          </ul>
        </li>
        <li>
          <b>N-grams:</b>
          <ul>
            <li>Вместо отдельных слов анализируются последовательности из N слов (биграммы, триграммы и т.д.), что позволяет учитывать некоторые аспекты порядка слов.</li>
            <li><b>Пример:</b> "машинное обучение" как биграмма будет представлено как отдельный токен, что помогает сохранить некоторый контекст.</li>
          </ul>
        </li>
      </ol><br>
      <p>Bag of Words (BoW) является фундаментальным методом параметризации текстов, который, несмотря на свои ограничения, остается важным и полезным инструментом в арсенале специалистов по обработке естественного языка и машинному обучению. Понимание его принципов, достоинств и недостатков, а также знание современных альтернатив позволяет эффективно решать широкий спектр задач, связанных с анализом текстов.</p>
    </div>
  </details>

  <!-- 14 -->
  <details class="details">
    <summary class="details__title">Embedding-слой. Основные параметры слоя.</summary>
    <div class="details__content">
      <p>Embedding-слой в нейронных сетях — это слой, который преобразует категориальные данные, такие как слова, в плотные векторы фиксированной размерности. Этот слой часто используется в задачах обработки естественного языка (NLP) для представления слов в виде векторов в многомерном пространстве, что позволяет моделям учитывать семантическую информацию.</p>
      <br>
      <p><b>Основная идея</b></p>
      <p>Embedding-слой берет на вход последовательность индексов (например, индексов слов) и отображает каждый индекс в плотный вектор фиксированной размерности. Эти векторы обычно обучаются вместе с нейронной сетью и оптимизируются таким образом, чтобы кодировать семантическую информацию о словах.</p>
      <br>
      <ol><b>Принцип работы</b>
        <li><b>Вход:</b> Последовательность индексов, представляющих слова.</li>
        <li><b>Выход:</b> Плотные векторы фиксированной размерности для каждого входного индекса.</li>
      </ol><br><br>
      <ol><b>Основные параметры Embedding-слоя</b>
        <li>
          <b>input_dim (размер входного словаря):</b>
          <ul>
            <li>Определяет количество уникальных слов или токенов, которые могут быть закодированы в векторы.</li>
            <li>Это число обычно равно размеру словаря + 1, где 1 добавляется для учета возможного токена "неизвестное слово".</li>
            <li>Например, если словарь содержит 10 000 уникальных слов, input_dim будет равно 10 001.</li>
          </ul>
        </li>
        <li>
          <b>output_dim (размерность векторов):</b>
          <ul>
            <li>Определяет размерность выходных векторов.</li>
            <li>Это число указывает, сколько чисел будет в векторе, представляющем каждое слово.</li>
            <li>Обычно выбирается в диапазоне от 50 до 300, в зависимости от задачи и объема данных.</li>
          </ul>
        </li>
        <li>
          <b>input_length (длина входной последовательности):</b>
          <ul>
            <li>Длина последовательности, которую будет принимать Embedding-слой.</li>
            <li>Это число указывает, сколько слов будет в каждой входной последовательности.</li>
            <li>Например, если модель принимает предложения длиной до 100 слов, input_length будет равно 100.</li>
          </ul>
        </li>
        <li>
          <b>embeddings_initializer (инициализация векторов):</b>
          <ul>
            <li>Способ инициализации весов Embedding-слоя.</li>
            <li>Можно использовать стандартные методы инициализации, такие как 'uniform' или 'normal', или специальные методы, разработанные для векторов встраивания, такие как Glorot или He.</li>
          </ul>
        </li>
        <li>
          <b>embeddings_regularizer (регуляризация векторов):</b>
          <ul>
            <li>Регуляризатор для векторов встраивания.</li>
            <li>Может использоваться для предотвращения переобучения</li>
            <li>Например, L1 или L2 регуляризация.</li>
          </ul>
        </li>
        <li>
          <b>embeddings_constraint (ограничения на векторы):</b>
          <ul>
            <li>Ограничения, накладываемые на векторы встраивания.</li>
            <li>Например, можно ограничить нормы векторов, чтобы они не росли слишком большими.</li>
          </ul>
        </li>
        <li>
          <b>mask_zero (маскирование нулей):</b>
          <ul>
            <li>Булевый параметр, который указывает, должны ли нулевые значения быть замаскированы.</li>
            <li>Это полезно при работе с последовательностями переменной длины, где нули используются для выравнивания последовательностей до одинаковой длины.</li>
            <li>Если mask_zero=True, слой будет игнорировать нулевые значения при обучении.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol><b>Пример использования Embedding-слоя</b>
        <li>
          <b>Входной слой:</b>
          <ul>
            <li>Embedding-слой используется сразу после слоя ввода, принимая индексы слов и преобразуя их в векторы.</li>
          </ul>
        </li>
        <li>
          <b>Включение в модель:</b>
          <ul>
            <li>Embedding-слой можно интегрировать в более сложные модели, такие как рекуррентные нейронные сети (RNN) или сверточные нейронные сети (CNN) для обработки текстов.</li>
          </ul>
        </li>
      </ol><br><br>
      <ol><b>Преимущества Embedding-слоя</b>
        <li>
          <b>Уменьшение размерности:</b>
          <ul>
            <li>Векторы встраивания позволяют представлять слова в пространстве меньшей размерности по сравнению с one-hot кодированием, что уменьшает размерность входных данных и улучшает производительность модели.</li>
          </ul>
        </li>
        <li>
          <b>Обучение полезных признаков:</b>
          <ul>
            <li>Векторы встраивания обучаются так, чтобы близкие по смыслу слова имели похожие векторы, что позволяет моделям лучше понимать семантические связи между словами.</li>
          </ul>
        </li>
        <li>
          <b>Универсальность:</b>
          <ul>
            <li>Embedding-слой можно использовать для любой категории данных, а не только для слов, что делает его универсальным инструментом для работы с категориальными признаками.</li>
          </ul>
        </li>
      </ol>
      <br>
      <p>Embedding-слой является важным компонентом современных моделей обработки естественного языка, предоставляя эффективный и гибкий способ представления категориальных данных. Понимание его параметров и принципов работы позволяет создавать мощные модели для анализа текстов и других задач, требующих представления категориальных данных в виде плотных векторов.</p>
    </div>
  </details>

  <!-- 15 -->
  <details class="details">
    <summary class="details__title">Задача регрессии. Примеры. Подготовка данных, принцип построения архитектур НС для
      решения задачи.</summary>
    <div class="details__content">
      <p>Lorem ipsum dolor sit amet consectetur adipisicing elit. Earum omnis beatae itaque! Maxime consequuntur
        architecto, voluptatibus iste aliquid quaerat dolores, culpa repellendus optio omnis rem saepe quisquam
        incidunt, numquam molestias?</p>
    </div>
  </details>

  <!-- 16 -->
  <details class="details">
    <summary class="details__title">Способы сохранения/загрузки модели нейронной сети.</summary>
    <div class="details__content">
      <p>Lorem ipsum dolor sit amet consectetur adipisicing elit. Earum omnis beatae itaque! Maxime consequuntur
        architecto, voluptatibus iste aliquid quaerat dolores, culpa repellendus optio omnis rem saepe quisquam
        incidunt, numquam molestias?</p>
    </div>
  </details>

  <!-- 17 -->
  <details class="details">
    <summary class="details__title">Временный ряды. Инструмент TimeSeriesGenerator. Особенности формирования выборки.
    </summary>
    <div class="details__content">
      <p>Lorem ipsum dolor sit amet consectetur adipisicing elit. Earum omnis beatae itaque! Maxime consequuntur
        architecto, voluptatibus iste aliquid quaerat dolores, culpa repellendus optio omnis rem saepe quisquam
        incidunt, numquam molestias?</p>
    </div>
  </details>

  <!-- 18 -->
  <details class="details">
    <summary class="details__title">Аугментация изображений. Инструмент ImageDataGenerator.</summary>
    <div class="details__content">
      <p>Lorem ipsum dolor sit amet consectetur adipisicing elit. Earum omnis beatae itaque! Maxime consequuntur
        architecto, voluptatibus iste aliquid quaerat dolores, culpa repellendus optio omnis rem saepe quisquam
        incidunt, numquam molestias?</p>
    </div>
  </details>

  <!-- 19 -->
  <details class="details">
    <summary class="details__title">Инструмент Callback’ов. Встроенные Callback’и keras’а.</summary>
    <div class="details__content">
      <p>Lorem ipsum dolor sit amet consectetur adipisicing elit. Earum omnis beatae itaque! Maxime consequuntur
        architecto, voluptatibus iste aliquid quaerat dolores, culpa repellendus optio omnis rem saepe quisquam
        incidunt, numquam molestias?</p>
    </div>
  </details>

  <!-- 20 -->
  <details class="details">
    <summary class="details__title">Архитектура U-Net. Принцип построения.</summary>
    <div class="details__content">
      <p>Lorem ipsum dolor sit amet consectetur adipisicing elit. Earum omnis beatae itaque! Maxime consequuntur
        architecto, voluptatibus iste aliquid quaerat dolores, culpa repellendus optio omnis rem saepe quisquam
        incidunt, numquam molestias?</p>
    </div>
  </details>

  <!-- 21 -->
  <details class="details">
    <summary class="details__title">Сегментация изображений.</summary>
    <div class="details__content">
      <p>Lorem ipsum dolor sit amet consectetur adipisicing elit. Earum omnis beatae itaque! Maxime consequuntur
        architecto, voluptatibus iste aliquid quaerat dolores, culpa repellendus optio omnis rem saepe quisquam
        incidunt, numquam molestias?</p>
    </div>
  </details>

  <!-- 22 -->
  <details class="details">
    <summary class="details__title">Рекуррентные нейронные сети. Слой LSTM.</summary>
    <div class="details__content">
      <p>Lorem ipsum dolor sit amet consectetur adipisicing elit. Earum omnis beatae itaque! Maxime consequuntur
        architecto, voluptatibus iste aliquid quaerat dolores, culpa repellendus optio omnis rem saepe quisquam
        incidunt, numquam molestias?</p>
    </div>
  </details>

  <!-- 23 -->
  <details class="details">
    <summary class="details__title">Создание и разработка телеграм-бота.</summary>
    <div class="details__content">
      <p>Lorem ipsum dolor sit amet consectetur adipisicing elit. Earum omnis beatae itaque! Maxime consequuntur
        architecto, voluptatibus iste aliquid quaerat dolores, culpa repellendus optio omnis rem saepe quisquam
        incidunt, numquam molestias?</p>
    </div>
  </details>

  <!-- 24 -->
  <details class="details">
    <summary class="details__title">Функции и кнопки телеграм-бота. Взаимодействие с ботом.</summary>
    <div class="details__content">
      <p>Lorem ipsum dolor sit amet consectetur adipisicing elit. Earum omnis beatae itaque! Maxime consequuntur
        architecto, voluptatibus iste aliquid quaerat dolores, culpa repellendus optio omnis rem saepe quisquam
        incidunt, numquam molestias?</p>
    </div>
  </details>

  <!-- 25 -->
  <details class="details">
    <summary class="details__title">Методы распознавания и генерации речи.</summary>
    <div class="details__content">
      <p>Lorem ipsum dolor sit amet consectetur adipisicing elit. Earum omnis beatae itaque! Maxime consequuntur
        architecto, voluptatibus iste aliquid quaerat dolores, culpa repellendus optio omnis rem saepe quisquam
        incidunt, numquam molestias?</p>
    </div>
  </details>

  <!-- 26 -->
  <details class="details">
    <summary class="details__title">ChatGPT. Основы дообучения. Роли ChatGPT.</summary>
    <div class="details__content">
      <p>Lorem ipsum dolor sit amet consectetur adipisicing elit. Earum omnis beatae itaque! Maxime consequuntur
        architecto, voluptatibus iste aliquid quaerat dolores, culpa repellendus optio omnis rem saepe quisquam
        incidunt, numquam molestias?</p>
    </div>
  </details>

  <!-- 27 -->
  <details class="details">
    <summary class="details__title">Обнаружение объектов. Принцип построения архитектуры YOLO.</summary>
    <div class="details__content">
      <p>Lorem ipsum dolor sit amet consectetur adipisicing elit. Earum omnis beatae itaque! Maxime consequuntur
        architecto, voluptatibus iste aliquid quaerat dolores, culpa repellendus optio omnis rem saepe quisquam
        incidunt, numquam molestias?</p>
    </div>
  </details>

  <!-- 28 -->
  <details class="details">
    <summary class="details__title">Методы работы с изображениями и видео.</summary>
    <div class="details__content">
      <p>Lorem ipsum dolor sit amet consectetur adipisicing elit. Earum omnis beatae itaque! Maxime consequuntur
        architecto, voluptatibus iste aliquid quaerat dolores, culpa repellendus optio omnis rem saepe quisquam
        incidunt, numquam molestias?</p>
    </div>
  </details>

  <!-- 29 -->
  <details class="details">
    <summary class="details__title">Структура файлов и папок в задаче Object Detection.</summary>
    <div class="details__content">
      <p>Lorem ipsum dolor sit amet consectetur adipisicing elit. Earum omnis beatae itaque! Maxime consequuntur
        architecto, voluptatibus iste aliquid quaerat dolores, culpa repellendus optio omnis rem saepe quisquam
        incidunt, numquam molestias?</p>
    </div>
  </details>

  <!-- 30 -->
  <details class="details">
    <summary class="details__title">Распознавание текста на изображениях.</summary>
    <div class="details__content">
      <p>Lorem ipsum dolor sit amet consectetur adipisicing elit. Earum omnis beatae itaque! Maxime consequuntur
        architecto, voluptatibus iste aliquid quaerat dolores, culpa repellendus optio omnis rem saepe quisquam
        incidunt, numquam molestias?</p>
    </div>
  </details>

  <!-- 31 -->
  <details class="details">
    <summary class="details__title">AutoML(фреймворки, задачи).</summary>
    <div class="details__content">
      <p>Lorem ipsum dolor sit amet consectetur adipisicing elit. Earum omnis beatae itaque! Maxime consequuntur
        architecto, voluptatibus iste aliquid quaerat dolores, culpa repellendus optio omnis rem saepe quisquam
        incidunt, numquam molestias?</p>
    </div>
  </details>

  <!-- 32 -->
  <details class="details">
    <summary class="details__title">Готовые решения для сегментации изображений. Дообучение.</summary>
    <div class="details__content">
      <p>Lorem ipsum dolor sit amet consectetur adipisicing elit. Earum omnis beatae itaque! Maxime consequuntur
        architecto, voluptatibus iste aliquid quaerat dolores, culpa repellendus optio omnis rem saepe quisquam
        incidunt, numquam molestias?</p>
    </div>
  </details>
  <script src="scripts/main.js"></script>
</body>

</html>